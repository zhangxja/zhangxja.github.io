{
    "version": "https://jsonfeed.org/version/1",
    "title": "红尘小筑",
    "subtitle": "天高任鸟飞",
    "icon": "https://zhangxja.github.io/images/favicon.ico",
    "description": "红尘滚滚，偏安一隅，怡然自得",
    "home_page_url": "https://zhangxja.github.io",
    "items": [
        {
            "id": "https://zhangxja.github.io/2025/07/22/ai/1.RAG%E5%85%A5%E9%97%A8%E4%B8%8E%E4%BB%8E%E9%9B%B6%E5%88%B0%E4%B8%80%E6%90%AD%E5%BB%BARAG%E7%B3%BB%E7%BB%9F/",
            "url": "https://zhangxja.github.io/2025/07/22/ai/1.RAG%E5%85%A5%E9%97%A8%E4%B8%8E%E4%BB%8E%E9%9B%B6%E5%88%B0%E4%B8%80%E6%90%AD%E5%BB%BARAG%E7%B3%BB%E7%BB%9F/",
            "title": "AI分类",
            "date_published": "2025-07-22T01:01:03.569Z",
            "content_html": "<h2 id=\"一-ragretrieval-augmented-generation检索增强生成技术综述\"><a class=\"anchor\" href=\"#一-ragretrieval-augmented-generation检索增强生成技术综述\">#</a> 一、RAG（Retrieval-Augmented Generation，检索增强生成）技术综述</h2>\n<p>  RAG，Retrieval-Augmented Generation，也被称作检索增强生成技术，最早在 Facebook AI（Meta AI）在 2020 年发表的论文《Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks》（ <span class=\"exturl\" data-url=\"aHR0cHM6Ly9hcnhpdi5vcmcvYWJzLzIwMDUuMTE0MDE=\">https://arxiv.org/abs/2005.11401</span> ）中正式提出，这种方法的核心思想是借助一些文本检索策略，让大模型每次问答前都带入相关文本，以此来改善大模型回答时的准确性。这项技术刚发布时并未引发太大关注，而伴随 2022 年大模型技术大爆发，RAG 技术才逐渐进入人们视野，并且由于早期大模型技术应用均已 “知识库问答” 为主，而 RAG 技术是最易上手、并且上限极高的技术，因此很快就成为了大模型技术人必备的技术之一。</p>\n<h3 id=\"1rag技术极简实现流程\"><a class=\"anchor\" href=\"#1rag技术极简实现流程\">#</a> 1.RAG 技术极简实现流程</h3>\n<p>  时至今日，RAG 技术已经是非常庞大的技术体系了，从简答的文档切分、存储、匹配，再到复杂的入 GraphRAG（基于知识图谱的检索增强），以及复杂文档解析 + 多模态识别技术等等等等。<br>\n<img data-src=\"https://pictes.oss-cn-beijing.aliyuncs.com/LLM/rh5rzr.png\" alt=\"image-20250708010422027\" style=\"zoom:33%;\" /></p>\n<p>而对于初学者来说，为了更好的上手学习 RAG 技术，我们首先需要对 RAG 技术最简单的实现形式有个基础的了解。一个最简单的 RAG 技术实现流程如下所示：<br>\n<img data-src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20231218182814731.png\" alt=\"image-20231218182814731\" style=\"zoom:33%;\" /></center></p>\n<p>我们需要围绕给定的文档（往往是非常长的文档）先进行切分，然后将切分的文档转化为计算机能识别的形式，也就是将其转化为一个数值型向量（也被称为词向量），然后当用户询问问题的时候，我们再将用户的问题转化为词向量，并和段落文档的词向量进行相似度匹配，借此找出和当前用户问题最相关的原始文档片段，然后将用户的问题和匹配的到的原文片段都带入大模型，进行最终的问答。由此便可实现一次完整的文档检索增强执行流程。</p>\n<p>  具体执行过程如下所示：</p>\n<center><center><img data-src=\"https://pictes.oss-cn-beijing.aliyuncs.com/LLM/image-20250708015352331.png\" alt=\"image-20250708015352331\" style=\"zoom:50%;\" />\n<h3 id=\"2rag技术核心应用场景拓展模型知识边界与减少问答幻觉\"><a class=\"anchor\" href=\"#2rag技术核心应用场景拓展模型知识边界与减少问答幻觉\">#</a> 2.RAG 技术核心应用场景：拓展模型知识边界与减少问答幻觉</h3>\n<p>  那这样的一个检索增强流程到底有什么用呢？这就不得不从当代大模型本身的三项技术缺陷开始说起了。</p>\n<ul>\n<li>缺陷一：大模型幻觉</li>\n</ul>\n<p>  相信大家在使用大模型的时候，都会遇到大模型无中生有胡编乱造答案的情况，例如胡乱生成一些概念、一些论文甚至是一些实时等，这就是所谓的大模型幻觉。</p>\n<center><img data-src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202507072338105.png\" alt=\"image-20250707233838007\" style=\"zoom:50%;\" />\n<p>而其中，第一代 DeepSeek R1 模型的幻觉是非常严重的，平均七次回答中就会有一次的回答存在幻觉，这可以说是第一版 R1 模型最大的短板。</p>\n<p>  大型语言模型之所以会产生幻觉，主要是因为它们的训练方式和内在机制决定了它们并不具备真正理解和验证事实的能力。模型在训练过程中，通过分析大规模文本数据来学习不同词语和句子之间的概率关系，也就是在某种程度上掌握 “在什么上下文中，什么样的回答听起来更合理”。然而，模型并没有接入实时的知识库或事实核查工具，当它遇到陌生的问题、模糊的描述或者上下文不完整的输入时，就会基于概率和语料库中似是而非的关联去 “编造” 一个看似正确的答案。由于这些输出往往语法流畅、逻辑连贯，人类读者很容易误以为它是真实可信的内容，这就是我们通常说的 “模型幻觉”。</p>\n<ul>\n<li>缺陷二：有限的最大上下文</li>\n</ul>\n<p>  而除此之外，大模型在实际应用中还会另一个 “障碍”，那就是最大上下文限制。由于大模型的本质其实是一个算法，不管是让大模型 “知道” 有哪些外部工具，还是要给大模型进行 “背景设置”，或者是要给模型添加历史对话消息，以及本次对话的输出，都需要占用这个上下文窗口。这就使得我们在一次对话中能够给大模型灌输的知识（文本）其实是有限的。</p>\n<p>  大型语言模型还存在最大上下文限制，这是由它们的架构和计算方式决定的。每次生成回答时，模型需要把输入文本转换成固定长度的数字序列（称为 token），并在内部一次性加载到模型的 “上下文窗口” 中进行处理。这个窗口的大小是有限的，不同模型一般在几千到几万 token 之间。如果输入内容超出这个长度，模型要么截断最前面的部分，要么丢弃部分信息，这就会造成对话历史、长文档或先前提到的重要细节的遗失。因为它无法跨越上下文窗口无限地保留信息，所以在面对长对话或者大量背景知识时，模型常常出现上下文断裂、回答不连贯或者忽略先前条件的情况。</p>\n<p>  早些时候的大模型普遍是 8k 最大上下文，相当于是 8-10 页中文 PDF，伴随着大模型预训练技术的不断发展，顶尖的大模型，如 Gemini 2.5 Pro 和 GPT-4.1 等模型，已经达到了 1M 的最大上下文长度，相当于是一千页的 PDF，相当于 1.5 本《红楼梦》，而普通的模型，也基本达到 64K 或 128K 最大上下文，相当于 60-100 也左右的 PDF。</p>\n<center><img data-src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202507072348046.png\" alt=\"image-20250707234800964\" style=\"zoom:33%;\" />\n<p>但是，模型上下文的增长也是有限度的，对于开发者来说，能够一次性输入的信息都会有限制。</p>\n<ul>\n<li>缺陷三：模型专业知识与时效性知识不足</li>\n</ul>\n<p>  大型语言模型虽然在通用领域展现出令人瞩目的语言理解和生成能力，但其在特定领域的专业知识掌握往往存在明显局限。其根本原因在于，模型的训练依赖于预先收集的大规模语料，这些语料覆盖面虽广，却很难保证在所有专业领域中具有足够的深度和准确性。某些领域，如医学、法律或前沿科技，知识更新速度快且门槛较高，公开可获取的高质量数据本身就有限，模型难以在此基础上形成系统性和权威性的认知。此外，模型训练通常在固定的时间点结束，因此其所掌握的知识具有天然的时效性，无法实时反映新近出现的研究成果、政策变化或行业动态。这种静态的知识存储模式，决定了大模型在面对最新或高度专业化的问题时，往往难以提供全面、精确的解答。</p>\n<center><img data-src=\"https://pictes.oss-cn-beijing.aliyuncs.com/LLM/image-20250708022912484.png\" alt=\"image-20250708022912484\" style=\"zoom:50%;\" />\n<p>  基于此，我们再回顾 RAG 的技术实现流程，就不难发现其背后的技术价值了：如果我们能在每次对话的时候，为当前模型输入最精准的问题相关的文档，那就能拓展模型的知识边界，无论是提升模型专业知识的准确性、给模型灌输一些时效性的知识、或者消除模型幻觉，都将大有助益，而在其他一些对话场景中，无论是需要围绕海量的文本搭建本地问答知识库、还是在构建无限上下文的聊天机器人，RAG 技术都是最佳解决方案。</p>\n<h3 id=\"3-问答机器人标配rag系统\"><a class=\"anchor\" href=\"#3-问答机器人标配rag系统\">#</a> 3. 问答机器人标配：RAG 系统</h3>\n<p>  正因为知识库检索的广泛的使用需求，RAG 技术几乎成了现在各项聊天机器人的标配，无论是面向普通用户的聊天问答应用 Cherry Studio：</p>\n<center><img data-src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250708141040865.png\" alt=\"image-20250708141040865\" style=\"zoom:33%;\" />\n<p>还是面向企业应用场景的通用开源前端 Open-WebUI:</p>\n<center><img data-src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250708142841404.png\" alt=\"image-20250708142841404\" style=\"zoom:33%;\" />\n<p>都毫无例外都配置了 RAG 功能，而对于 OpenAI-WebUI 这种企业级前端，还为用户展示了 RAG 检索过程诸多技术细节：</p>\n<center><img data-src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250708143007552.png\" alt=\"image-20250708143007552\" style=\"zoom:33%;\" />\n<p>尽管这些项目能让用户更加快速的使用 RAG 系统，但这种传统的 RAG 流程（也被称作 Native RAG），在长期的应用过程中也逐渐展露出很多问题，例如对于非结构化的文本（例如包含图片、公式的文本）无法进行检索，而对于超大规模文本的检索又会存在精度不足、或者无法提炼总结跨文本概念等问题。为此，近两年的时间里，在无数技术人的共同努力下，RAG 技术有了长足的成长和突破。</p>\n<p>  我们团队自研的开源 Jupyter 智能体助教 MateGen Air，也提供了完整的公开课（部分）知识库问答功能：</p>\n<center><img data-src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250708155628356.png\" alt=\"image-20250708155628356\" style=\"zoom:33%;\" />\n<center><img data-src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250708155442209.png\" alt=\"image-20250708155442209\" style=\"zoom:33%;\" />\n<h3 id=\"4-rag全栈技术体系介绍\"><a class=\"anchor\" href=\"#4-rag全栈技术体系介绍\">#</a> 4. RAG 全栈技术体系介绍</h3>\n<p>  但是，就像前文介绍的那样，RAG 技术是一项应用面广、门槛很低、但同时上限也很高的一项技术。历经数年的技术发展，RAG 技术的体系已经非常庞大，以下是 RAG 技术全栈技术框架概览：</p>\n<center><img data-src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/88bac0891ac369368fd9199d1542862.png\" alt=\"88bac0891ac369368fd9199d1542862\" style=\"zoom:50%;\" />\n<ul>\n<li>GraphRAG</li>\n</ul>\n<p><strong>GraphRAG（Graph-enhanced Retrieval-Augmented Generation）</strong> 是一种在经典 RAG 基础上引入<strong>知识图谱 / 图结构</strong>的新型检索生成方法 。其核心思想是通过将文档或数据转换成图的形式，从而捕捉实体与实体之间的语义关系，并在检索阶段利用图遍历、关系推理等机制来辅助上下文构建，这种结构化信息能够提升语义理解和多跳推理能力。</p>\n<p>具体来说，GraphRAG 的流程包括：</p>\n<ol>\n<li><strong>图谱构建</strong>：将文本拆分为多个单元（TextUnit），提取实体与关系，构造知识图，并进行图社区检测与摘要；</li>\n<li><strong>混合检索</strong>：用户提问既可以进行向量检索定位实体，也可以通过图查询（如 Cypher/SPARQL）沿关系边扩展信息 ；</li>\n<li><strong>图增强生成</strong>：将检索到的节点、路径、社区摘要等信息拼接进 Prompt，引导 LLM 生成更准确、结构清晰、并基于事实推理的回答。</li>\n</ol>\n<table>\n<thead>\n<tr>\n<th>对比维度</th>\n<th>传统 RAG</th>\n<th>GraphRAG</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>检索方式</td>\n<td>基于向量语义相似度</td>\n<td>向量 + 知识图遍历 / 查询</td>\n</tr>\n<tr>\n<td>关系理解能力</td>\n<td>弱：只能匹配语义相近片段</td>\n<td>强：能理解实体之间的多跳关系与结构</td>\n</tr>\n<tr>\n<td>多跳推理支持</td>\n<td>弱：难以综合跨文档信息</td>\n<td>强：图结构天然支持推理路径遍历</td>\n</tr>\n<tr>\n<td>语义上下文覆盖</td>\n<td>依赖检索片段</td>\n<td>可检索完整实体子图、社区摘要</td>\n</tr>\n<tr>\n<td>可解释性</td>\n<td>中：返回片段但缺关键信息结构</td>\n<td>高：能显示实体关系路径及社区结构</td>\n</tr>\n<tr>\n<td>性能 / 复杂度</td>\n<td>低：直接使用向量库</td>\n<td>高：需要图构建、遍历、摘要等 pipeline</td>\n</tr>\n</tbody>\n</table>\n<p>传统 RAG 主要是 “先检索语义近似片段，再生成回答”，适合简单查询与短对话。但当问题需要 “连接多个事实”“推理关系链” 和 “洞察上下文结构” 时，传统 RAG 会显得力不从心，而 GraphRAG 正是为复杂推理场景设计的增强机制。</p>\n<ul>\n<li>Agentic RAG</li>\n</ul>\n<p>   <strong>Agentic RAG（Agentic Retrieval-Augmented Generation）</strong> 是一种在传统 RAG 基础上进一步扩展的增强范式，它将<strong>检索增强生成</strong>与<strong> Agent（智能体）能力</strong>有机结合，使大模型不仅能够基于外部知识库进行回答，还能够通过一系列自主决策和工具调用来完成复杂任务。与经典 RAG 的 “检索 + 拼接 + 生成” 线性流程不同，Agentic RAG 将 LLM 视为一个具备推理、规划和操作能力的智能体，它在对话过程中可以根据问题拆解子任务，先后执行多轮检索、知识整合、函数调用甚至外部 API 请求，再将结果动态组合成最终的答案。</p>\n<p>   在这个模式下，大模型可以主动提出接下来的检索需求，或根据中间推理结果迭代获取更多信息，形成 “循环式检索与生成” 的闭环工作流。例如，当用户提出复杂查询时，Agentic RAG 可以先调用检索工具定位候选内容，再使用工具对结果进行归纳或分类，必要时还会触发计算或外部查询操作，最后再汇总所有信息输出一个有依据的、分步骤的解答。</p>\n<p>   相比传统 RAG，Agentic RAG 不仅提升了回答准确性和透明度，也为多轮推理和跨知识库整合提供了更强的灵活性，是近年来大模型产品中非常重要的能力演进方向。</p>\n<h3 id=\"5-rag热门开源项目产品\"><a class=\"anchor\" href=\"#5-rag热门开源项目产品\">#</a> 5. RAG 热门开源项目 &amp; 产品</h3>\n<p>  而如果不打算自主开发，目前也有非常多 RAG 成熟的开源项目，可以直接作为 RAG 产品进行使用。</p>\n<h4 id=\"51-maxkb\"><a class=\"anchor\" href=\"#51-maxkb\">#</a> 5.1 MaxKB</h4>\n<p>  MaxKB（Max Knowledge Brain） 是一款开源的、面向企业级应用的智能知识库助手，深度集成了 RAG（Retrieval‑Augmented Generation） 管道和流程编排能力。它支持用户通过上传文档或自动爬取网页内容，系统会自动完成 分段、向量化检索 等流程，从而显著减少大模型回答时的 “幻觉” 风险，提升问答的准确性和可信度。</p>\n<p>  此外，MaxKB 配备了一个灵活的 Agentic Workflow 引擎和丰富的工具函数集，能够满足复杂业务场景下的智能流程编排需求。它支持与各类 LLM（如 OpenAI/Claude/Gemini、本地模型 Llama、Qwen）及第三方系统进行零代码集成，方便快速在企业内部构建智能客服、内部知识问答、学术研究助手等应用。</p>\n<p>  总之，MaxKB 提供了一个 “开箱即用” 的智能知识服务框架，技术中立且功能全面，适用于多样化企业场景，诸如客服、知识管理、教育及科研等。GPT 架构下通过 RAG 技术减少幻觉，并通过流程引擎强化业务能力，是一款值得企业部署的高效开源平台。但 MaxKB 只支持在线使用，数据隐私安全性难以得到保障，同时若想要创建更多知识库，还需要单独支付费用。</p>\n<center><img data-src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250708145321896.png\" alt=\"image-20250708145321896\" style=\"zoom:50%;\" />\n<center>\n<img data-src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250708145634936.png\" alt=\"image-20250708145634936\" style=\"zoom:50%;\" />\n<blockquote>\n<p>MaxKB 项目主页：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9naXRodWIuY29tLzFQYW5lbC1kZXYvTWF4S0I=\">https://github.com/1Panel-dev/MaxKB</span></p>\n</blockquote>\n<h4 id=\"52-ragflow\"><a class=\"anchor\" href=\"#52-ragflow\">#</a> 5.2 RAGFlow</h4>\n<p>  <strong>RAGFlow</strong> 是一款功能全面且高可配置的<strong>开源 RAG 引擎</strong>，专注于 “深度文档理解”（Deep Document Understanding），旨在帮助企业和开发者高效构建<strong>以文档为基础的智能问答系统</strong>。</p>\n<p>  它支持多种文档格式（如 PDF、Word、PPT、Excel、扫描件等），并以<strong>复杂布局识别</strong>和<strong> OCR 分块模板</strong>为核心，对文档进行结构化拆分，以生成适合检索的知识单元。</p>\n<p>  在检索阶段，RAGFlow 提供<strong>多路召回策略</strong>（包括向量检索和混合重排序），并生成<strong>可追溯的引用</strong>，能够显著减少模型幻觉，提高答案可信度。</p>\n<p>  在生成环节，它具备内置的<strong>流程引擎（Agentic Workflow）</strong>，结合 LLM 能够执行<strong>自动化推理任务</strong>（如代码执行、SQL 查询）。</p>\n<p>  技术架构上，RAGFlow 提供 Docker + Helm 快速部署能力，支持 x86 &amp; GPU 加速；并兼容主流 LLM 提供商与自部署选项，包括 OpenAI、Anthropic、Ollama、本地模型等。此外，它还配备交互式 Web UI 和低代码 Agent 搭建界面，用户可零代码创建知识库、上传文档、并生成可引用的对话助手或检索系统。</p>\n<center>\n<img data-src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250708145438954.png\" alt=\"image-20250708145438954\" style=\"zoom:50%;\" />\n<center><img data-src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250708145620056.png\" alt=\"image-20250708145620056\" style=\"zoom:50%;\" />\n<blockquote>\n<p>RAGFlow 项目主页：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9naXRodWIuY29tL2luZmluaWZsb3cvcmFnZmxvdy8=\">https://github.com/infiniflow/ragflow/</span></p>\n</blockquote>\n<h4 id=\"53-langchain-chatchat\"><a class=\"anchor\" href=\"#53-langchain-chatchat\">#</a> 5.3 LangChain-ChatChat</h4>\n<p>  <strong>LangChain‑Chatchat</strong>（原名 LangChain‑ChatGLM）是一款基于 LangChain 框架构建的开源、<strong>本地部署知识库问答与 Agent 应用</strong>平台，致力于在中文场景和开源大模型上提供流畅、可脱机运行的智能对话体验。它融合向量检索与生成式大模型，实现了完整的 RAG 问答流程，包括文档读取、内容分段、向量化检索、Top‑k 匹配，以及将检索出的内容与用户问题一起拼入 Prompt，驱动 LLM 生成答案。<br>\n  <br>\n该项目已支持主流开源 LLM（如 ChatGLM‑6B、GLM‑4-Chat、Qwen2‑Instruct、LLaMA 等）及 Embedding 模型，同时兼容多个本地推理框架（如 Xinference、Ollama、FastChat），也支持通过 OpenAI API 调用 GPT 模型。无论是在线还是离线环境，用户都能通过命令行或 Docker 快速部署，并自定义知识库路径和模型配置。</p>\n<p>在功能方面，LangChain‑Chatchat 提供：</p>\n<ul>\n<li>一站式知识库问答接口，支持文件、数据库、图片等多源输入；</li>\n<li>可控的 Agent 能力，支持工具调用与流程执行；</li>\n<li>丰富的 WebUI 与低代码交互方式，便于管理会话、系统提示词、检索配置等。</li>\n</ul>\n<center><img data-src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250708145818626.png\" alt=\"image-20250708145818626\" style=\"zoom: 50%;\" />\n<center><img data-src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250708145944355.png\" alt=\"image-20250708145944355\" style=\"zoom:50%;\" />\n<blockquote>\n<p>LangChain-chatchat 官网：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9naXRodWIuY29tL2NoYXRjaGF0LXNwYWNlL0xhbmdjaGFpbi1DaGF0Y2hhdA==\">https://github.com/chatchat-space/Langchain-Chatchat</span></p>\n</blockquote>\n<h3 id=\"6-rag系统开发框架\"><a class=\"anchor\" href=\"#6-rag系统开发框架\">#</a> 6. RAG 系统开发框架</h3>\n<ul>\n<li>最佳 RAG 系统开发开源框架：LangChain&amp;LangGraph</li>\n</ul>\n<p>  在当前的大模型应用开发生态中，<strong>LangChain</strong> 已经成为构建 RAG（Retrieval-Augmented Generation）系统最受欢迎的框架之一。LangChain 不仅提供了面向开发者的高层 API，还整合了<strong>文档加载、文本分块、向量检索、上下文拼接、输出解析</strong>等全流程工具，极大降低了 RAG 应用的开发门槛。在检索阶段，LangChain 提供了多种<strong> Document Loaders</strong>（如 PDF、Markdown、网页、数据库加载器），并内置了<strong> RecursiveCharacterTextSplitter</strong>、<strong>MarkdownHeaderTextSplitter</strong> 等分块工具，方便将原始文本转化为高质量的检索单元。向量化方面，LangChain 兼容主流 Embedding 模型（OpenAI Embedding、Hugging Face 模型、Cohere 等），并支持 Chroma、FAISS、Weaviate、Pinecone 等多种向量数据库无缝集成。</p>\n<p>  <br>\n在生成与问答环节，LangChain 封装了<strong> RetrievalQA</strong>、<strong>ConversationalRetrievalChain</strong>、<strong>MultiQueryRetriever</strong> 等常用组件，能够快速搭建基于单轮或多轮对话的检索增强问答系统。对于更高阶的能力，LangChain 还支持<strong> LLM Chain</strong> 与<strong> Agent</strong> 模式，开发者可以通过工具调用和多步骤推理，构建具备复杂交互逻辑的 Agentic RAG 系统。总体来看，LangChain 为 RAG 开发提供了丰富的工具集和模块化能力，使构建一个可扩展的知识检索与生成系统从 “几周工程” 缩短为 “几天内可原型验证”。</p>\n<center><img data-src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250708160451543.png\" alt=\"image-20250708160451543\" style=\"zoom:33%;\" />\n<ul>\n<li>新一代 Agents SDK、ADK 内置的在线 RAG 服务</li>\n</ul>\n<p>  在最新的大模型技术体系中，<strong>OpenAI Agent SDK</strong> 和 ** 谷歌 Agent Development Kit（ADK）*<em> 分别代表了两大云平台对 *<em> 检索增强生成（RAG）能力的官方支持路径</em></em>，两者虽然同属 “Agent+RAG” 范式，但在功能侧重点和生态整合方面各有特色。</p>\n<p>  OpenAI Agent SDK 通过<strong>原生 File Search</strong> 机制，为开发者提供了极简化的 RAG 接入方式。用户仅需在 Assistant 配置中启用文件检索工具，便可实现自动分块、向量化与高效召回，整个过程在 OpenAI 云端一体化托管，无需额外配置数据库或索引管理。该模式支持多轮对话的上下文跟踪和结果拼接，能够与 Function Calling 无缝结合，实现 “先检索后调用工具” 的闭环逻辑，尤其适合对系统稳定性和开发便捷性要求较高的场景。</p>\n<center><img data-src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250708160809504.png\" alt=\"image-20250708160809504\" style=\"zoom:33%;\" />\n<p>  相比之下，谷歌 ADK 则在<strong>多模态检索与推理流水线</strong>方面提供了更强的灵活性。其核心能力之一 “Grounding” 不仅支持文本向量检索，还能原生处理 PDF、表格、扫描件等多模态数据，并提供自动可追溯引用功能，使答案生成过程更加透明可信。ADK 允许开发者通过流水线（Pipeline）将检索、摘要、分类等步骤串联组合，构建复杂的多步推理流程，并支持与谷歌云生态（Drive、Gmail、Cloud Storage）深度集成。</p>\n<p>  总体而言，OpenAI Agent SDK 更加专注于 “一体化、低门槛的 RAG 体验”，而谷歌 ADK 则以 “多模态、可编排、高可扩展性” 为核心定位。两者均标志着 RAG 技术从最初的工程框架（如 LangChain、LlamaIndex）走向平台原生支持，也体现了未来智能体开发将更加重视知识检索、自动推理和可追溯性等能力的趋势。</p>\n<center><center>\n<img data-src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250708160717256.png\" alt=\"image-20250708160717256\" style=\"zoom:33%;\" />\n<h2 id=\"二-从零到一手动搭建rag系统\"><a class=\"anchor\" href=\"#二-从零到一手动搭建rag系统\">#</a> 二、从零到一手动搭建 RAG 系统</h2>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">import</span> os</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">from</span> openai <span class=\"token keyword\">import</span> OpenAI</pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt</pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np</pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token keyword\">from</span> typing <span class=\"token keyword\">import</span> Dict<span class=\"token punctuation\">,</span> List<span class=\"token punctuation\">,</span> Optional<span class=\"token punctuation\">,</span> Tuple<span class=\"token punctuation\">,</span> Union</pre></td></tr><tr><td data-num=\"6\"></td><td><pre></pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token keyword\">import</span> PyPDF2</pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token keyword\">import</span> markdown</pre></td></tr><tr><td data-num=\"9\"></td><td><pre><span class=\"token keyword\">import</span> html2text</pre></td></tr><tr><td data-num=\"10\"></td><td><pre><span class=\"token keyword\">import</span> json</pre></td></tr><tr><td data-num=\"11\"></td><td><pre><span class=\"token keyword\">from</span> tqdm <span class=\"token keyword\">import</span> tqdm</pre></td></tr><tr><td data-num=\"12\"></td><td><pre><span class=\"token keyword\">import</span> tiktoken</pre></td></tr><tr><td data-num=\"13\"></td><td><pre><span class=\"token keyword\">import</span> re</pre></td></tr><tr><td data-num=\"14\"></td><td><pre><span class=\"token keyword\">from</span> bs4 <span class=\"token keyword\">import</span> BeautifulSoup</pre></td></tr><tr><td data-num=\"15\"></td><td><pre><span class=\"token keyword\">from</span> IPython<span class=\"token punctuation\">.</span>display <span class=\"token keyword\">import</span> display<span class=\"token punctuation\">,</span> Code<span class=\"token punctuation\">,</span> Markdown</pre></td></tr></table></figure><figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>api_key <span class=\"token operator\">=</span> <span class=\"token string\">'your-openai-api-key'</span></pre></td></tr></table></figure><figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 实例化客户端</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>client <span class=\"token operator\">=</span> OpenAI<span class=\"token punctuation\">(</span>api_key<span class=\"token operator\">=</span>api_key<span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>                base_url<span class=\"token operator\">=</span><span class=\"token string\">\"https://ai.devtool.tech/proxy/v1\"</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 临时设置环境变量</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>os<span class=\"token punctuation\">.</span>environ<span class=\"token punctuation\">[</span><span class=\"token string\">\"OPENAI_API_KEY\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token string\">'your-openai-api-key'</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>os<span class=\"token punctuation\">.</span>environ<span class=\"token punctuation\">[</span><span class=\"token string\">\"OPENAI_BASE_URL\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token string\">\"https://ai.devtool.tech/proxy/v1\"</span></pre></td></tr></table></figure><p>  正如此前所说，在自然语言处理和机器学习领域中，Embedding 是将文本转化为数值向量的常用方法。通过这种方式，模型可以衡量不同文本之间的相似性，进而应用于如搜索、分类、推荐等多个领域。OpenAI 刚刚发布了其第三代 Embedding 模型，这些模型具有更高的性能、更低的成本，且在多语言处理上表现出色。以下是关于 OpenAI 新一代 Embedding 模型的详细介绍和调用方法。</p>\n<h3 id=\"1openai-embedding-模型简介\"><a class=\"anchor\" href=\"#1openai-embedding-模型简介\">#</a> 1.OpenAI Embedding 模型简介</h3>\n<p>  <strong>Embedding</strong> 是将文本字符串表示为向量（浮点数列表），通过计算向量之间的距离来衡量文本之间的相关性。向量距离越小，表示文本之间的相关性越高；距离越大，相关性越低。常见的 Embedding 应用包括：</p>\n<ul>\n<li><strong>搜索</strong>：根据文本查询的相关性对结果进行排序</li>\n<li><strong>聚类</strong>：根据文本相似性将其分组</li>\n<li><strong>推荐</strong>：根据相关文本字符串推荐项目</li>\n<li><strong>异常检测</strong>：识别与其他内容相关性较低的异常点</li>\n<li><strong>多样性测量</strong>：分析相似性分布</li>\n<li><strong>分类</strong>：将文本字符串根据其最相似的标签进行分类</li>\n</ul>\n<p>OpenAI 最新的 Embedding 模型包括 <strong>text-embedding-3-small</strong> 和 <strong>text-embedding-3-large</strong>，它们比以往的模型具有更高的性能，且支持更多语言。这两个模型分别生成长度为 1536 和 3072 的向量。此外，用户可以通过设置维度参数来减少向量的维度，而不损失其表示概念的能力。</p>\n<h3 id=\"2openai-embedding模型获取方法\"><a class=\"anchor\" href=\"#2openai-embedding模型获取方法\">#</a> 2.OpenAI Embedding 模型获取方法</h3>\n<p>  要获取文本的 Embedding 向量，可以将文本字符串发送到 OpenAI 的 Embedding API 端点，并指定所使用的模型（例如  <code>text-embedding-3-small</code> ）。响应结果将包含 Embedding 向量，以及一些额外的元数据信息。</p>\n<p>  截止目前，OpenAI 提供了两个第三代 Embedding 模型，定价基于输入的 token 数量。以下是关于模型性能与定价的概览：</p>\n<table>\n<thead>\n<tr>\n<th>模型</th>\n<th>每美元支持的页面数量</th>\n<th>在 MTEB 测试中的表现</th>\n<th>最大输入 token 数量</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>text-embedding-3-small</td>\n<td>62,500</td>\n<td>62.3%</td>\n<td>8191</td>\n</tr>\n<tr>\n<td>text-embedding-3-large</td>\n<td>9,615</td>\n<td>64.6%</td>\n<td>8191</td>\n</tr>\n<tr>\n<td>text-embedding-ada-002</td>\n<td>12,500</td>\n<td>61.0%</td>\n<td>8191</td>\n</tr>\n</tbody>\n</table>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 调用 embedding API 获取文本的向量表示</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>response <span class=\"token operator\">=</span> client<span class=\"token punctuation\">.</span>embeddings<span class=\"token punctuation\">.</span>create<span class=\"token punctuation\">(</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    <span class=\"token builtin\">input</span><span class=\"token operator\">=</span><span class=\"token string\">\"测试文本\"</span><span class=\"token punctuation\">,</span>  <span class=\"token comment\"># 输入文本</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    model<span class=\"token operator\">=</span><span class=\"token string\">\"text-embedding-3-small\"</span>  <span class=\"token comment\"># 选择 Embedding 模型</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 打印返回的 embedding 向量</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>response<span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>embedding<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><pre><code>[0.0060808719135820866, 0.01937379501760006, 0.01978626847267151, -0.04902195185422897, 0.005962129216641188, -0.05264672636985779, -0.026648342609405518, -0.02018624357879162, 0.061296187341213226, -0.007674522697925568, -0.009818139486014843, -0.021473664790391922, 0.030473103746771812, 0.024323487654328346, 0.012936695478856564, 0.010143118910491467, -0.034522853791713715, -0.012192991562187672, -0.0307230893522501, -0.03832261636853218, -0.03187301754951477, -0.011080560274422169]\n</code></pre>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>response<span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>embedding<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><pre><code>1536\n</code></pre>\n<p>返回的 Embedding 向量可以直接用于多种应用场景，例如存储在向量数据库中，进行文本相似度搜索等。默认情况下， <code>text-embedding-3-small</code>  生成的向量长度为 1536， <code>text-embedding-3-large</code>  的向量长度为 3072。</p>\n<ul>\n<li>\n<p>余弦相似度介绍与效果简介</p>\n</li>\n<li>\n<p>欧氏距离与余弦相似度计算公式</p>\n</li>\n</ul>\n<p>  假设现有 a、b 两个向量：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mover accent=\"true\"><mi>a</mi><mo>⃗</mo></mover><mo>=</mo><mo stretchy=\"false\">[</mo><msub><mi>a</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>a</mi><mn>2</mn></msub><mo separator=\"true\">,</mo><msub><mi>a</mi><mn>3</mn></msub><mo separator=\"true\">,</mo><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">\\vec{a} = [a_1, a_2, a_3, ...]\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.2355em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z'/></svg></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">3</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">.</span><span class=\"mord\">.</span><span class=\"mord\">.</span><span class=\"mclose\">]</span></span></span></span></span></p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mover accent=\"true\"><mi>b</mi><mo>⃗</mo></mover><mo>=</mo><mo stretchy=\"false\">[</mo><msub><mi>b</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>b</mi><mn>2</mn></msub><mo separator=\"true\">,</mo><msub><mi>b</mi><mn>3</mn></msub><mo separator=\"true\">,</mo><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">\\vec{b} = [b_1, b_2, b_3, ...]\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.9774399999999999em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9774399999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span></span></span><span style=\"top:-3.26344em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.2355em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z'/></svg></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathnormal\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">3</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">.</span><span class=\"mord\">.</span><span class=\"mord\">.</span><span class=\"mclose\">]</span></span></span></span></span></p>\n<p>余弦相似度计算公式为：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mtext>Cosine Similarity</mtext><mo stretchy=\"false\">(</mo><mover accent=\"true\"><mi>a</mi><mo>⃗</mo></mover><mo separator=\"true\">,</mo><mover accent=\"true\"><mi>b</mi><mo>⃗</mo></mover><mo stretchy=\"false\">)</mo><mo>=</mo><mfrac><mrow><mover accent=\"true\"><mi>a</mi><mo>⃗</mo></mover><mo>⋅</mo><mover accent=\"true\"><mi>b</mi><mo>⃗</mo></mover></mrow><mrow><mi mathvariant=\"normal\">∥</mi><mover accent=\"true\"><mi>a</mi><mo>⃗</mo></mover><mi mathvariant=\"normal\">∥</mi><mi mathvariant=\"normal\">∥</mi><mover accent=\"true\"><mi>b</mi><mo>⃗</mo></mover><mi mathvariant=\"normal\">∥</mi></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\text{Cosine Similarity} (\\vec{a}, \\vec{b}) = \\frac{\\vec{a} \\cdot \\vec{b}}{\\|\\vec{a}\\| \\|\\vec{b}\\|}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.2274399999999999em;vertical-align:-0.25em;\"></span><span class=\"mord text\"><span class=\"mord\">Cosine Similarity</span></span><span class=\"mopen\">(</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.2355em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z'/></svg></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9774399999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span></span></span><span style=\"top:-3.26344em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.2355em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z'/></svg></span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.7718799999999995em;vertical-align:-1.1174399999999998em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.65444em;\"><span style=\"top:-2.1325600000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">∥</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.2355em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z'/></svg></span></span></span></span></span></span></span><span class=\"mord\">∥</span><span class=\"mord\">∥</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9774399999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span></span></span><span style=\"top:-3.26344em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.2355em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z'/></svg></span></span></span></span></span></span></span><span class=\"mord\">∥</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.2355em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z'/></svg></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9774399999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span></span></span><span style=\"top:-3.26344em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.2355em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z'/></svg></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.1174399999999998em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n<p>  其中：</p>\n<ul>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mover accent=\"true\"><mi>a</mi><mo>⃗</mo></mover><mo>⋅</mo><mover accent=\"true\"><mi>b</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{a} \\cdot \\vec{b}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.2355em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z'/></svg></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.9774399999999999em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9774399999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span></span></span><span style=\"top:-3.26344em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.2355em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z'/></svg></span></span></span></span></span></span></span></span></span></span> 表示向量 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mover accent=\"true\"><mi>a</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{a}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.2355em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z'/></svg></span></span></span></span></span></span></span></span></span></span> 和向量 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mover accent=\"true\"><mi>b</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{b}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.9774399999999999em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9774399999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span></span></span><span style=\"top:-3.26344em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.2355em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z'/></svg></span></span></span></span></span></span></span></span></span></span> 的点积。</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"normal\">∥</mi><mover accent=\"true\"><mi>a</mi><mo>⃗</mo></mover><mi mathvariant=\"normal\">∥</mi></mrow><annotation encoding=\"application/x-tex\">\\|\\vec{a}\\|</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">∥</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.2355em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z'/></svg></span></span></span></span></span></span></span><span class=\"mord\">∥</span></span></span></span> 和 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"normal\">∥</mi><mover accent=\"true\"><mi>b</mi><mo>⃗</mo></mover><mi mathvariant=\"normal\">∥</mi></mrow><annotation encoding=\"application/x-tex\">\\|\\vec{b}\\|</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.2274399999999999em;vertical-align:-0.25em;\"></span><span class=\"mord\">∥</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9774399999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span></span></span><span style=\"top:-3.26344em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.2355em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z'/></svg></span></span></span></span></span></span></span><span class=\"mord\">∥</span></span></span></span> 分别是向量 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mover accent=\"true\"><mi>a</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{a}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.2355em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z'/></svg></span></span></span></span></span></span></span></span></span></span> 和 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mover accent=\"true\"><mi>b</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{b}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.9774399999999999em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9774399999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span></span></span><span style=\"top:-3.26344em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.2355em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z'/></svg></span></span></span></span></span></span></span></span></span></span> 的模（长度）。</li>\n</ul>\n<p>  点积 (Dot Product) 定义为：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mover accent=\"true\"><mi>a</mi><mo>⃗</mo></mover><mo>⋅</mo><mover accent=\"true\"><mi>b</mi><mo>⃗</mo></mover><mo>=</mo><msub><mi>a</mi><mn>1</mn></msub><msub><mi>b</mi><mn>1</mn></msub><mo>+</mo><msub><mi>a</mi><mn>2</mn></msub><msub><mi>b</mi><mn>2</mn></msub><mo>+</mo><mo>…</mo><mo>+</mo><msub><mi>a</mi><mi>n</mi></msub><msub><mi>b</mi><mi>n</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\vec{a} \\cdot \\vec{b} = a_1b_1 + a_2b_2 + \\ldots + a_nb_n\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.2355em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z'/></svg></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.9774399999999999em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9774399999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span></span></span><span style=\"top:-3.26344em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.2355em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z'/></svg></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.66666em;vertical-align:-0.08333em;\"></span><span class=\"minner\">…</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span></p>\n<p>  向量的模 (Magnitude) 定义为：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi mathvariant=\"normal\">∥</mi><mover accent=\"true\"><mi>a</mi><mo>⃗</mo></mover><mi mathvariant=\"normal\">∥</mi><mo>=</mo><msqrt><mrow><msubsup><mi>a</mi><mn>1</mn><mn>2</mn></msubsup><mo>+</mo><msubsup><mi>a</mi><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mo>…</mo><mo>+</mo><msubsup><mi>a</mi><mi>n</mi><mn>2</mn></msubsup></mrow></msqrt></mrow><annotation encoding=\"application/x-tex\">\\|\\vec{a}\\| = \\sqrt{a_1^2 + a_2^2 + \\ldots + a_n^2}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">∥</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.2355em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z'/></svg></span></span></span></span></span></span></span><span class=\"mord\">∥</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.84em;vertical-align:-0.5413249999999998em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.2986750000000002em;\"><span class=\"svg-align\" style=\"top:-3.8em;\"><span class=\"pstrut\" style=\"height:3.8em;\"></span><span class=\"mord\" style=\"padding-left:1em;\"><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7959080000000001em;\"><span style=\"top:-2.433692em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span><span style=\"top:-3.0448000000000004em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.26630799999999993em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7959080000000001em;\"><span style=\"top:-2.433692em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span><span style=\"top:-3.0448000000000004em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.26630799999999993em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"minner\">…</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.740108em;\"><span style=\"top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span><span style=\"top:-2.9890000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3.258675em;\"><span class=\"pstrut\" style=\"height:3.8em;\"></span><span class=\"hide-tail\" style=\"min-width:1.02em;height:1.8800000000000001em;\"><svg width='400em' height='1.8800000000000001em' viewBox='0 0 400000 1944' preserveAspectRatio='xMinYMin slice'><path d='M983 90\nl0 -0\nc4,-6.7,10,-10,18,-10 H400000v40\nH1013.1s-83.4,268,-264.1,840c-180.7,572,-277,876.3,-289,913c-4.7,4.7,-12.7,7,-24,7\ns-12,0,-12,0c-1.3,-3.3,-3.7,-11.7,-7,-25c-35.3,-125.3,-106.7,-373.3,-214,-744\nc-10,12,-21,25,-33,39s-32,39,-32,39c-6,-5.3,-15,-14,-27,-26s25,-30,25,-30\nc26.7,-32.7,52,-63,76,-91s52,-60,52,-60s208,722,208,722\nc56,-175.3,126.3,-397.3,211,-666c84.7,-268.7,153.8,-488.2,207.5,-658.5\nc53.7,-170.3,84.5,-266.8,92.5,-289.5z\nM1001 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.5413249999999998em;\"><span></span></span></span></span></span></span></span></span></span></p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi mathvariant=\"normal\">∥</mi><mover accent=\"true\"><mi>b</mi><mo>⃗</mo></mover><mi mathvariant=\"normal\">∥</mi><mo>=</mo><msqrt><mrow><msubsup><mi>b</mi><mn>1</mn><mn>2</mn></msubsup><mo>+</mo><msubsup><mi>b</mi><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mo>…</mo><mo>+</mo><msubsup><mi>b</mi><mi>n</mi><mn>2</mn></msubsup></mrow></msqrt></mrow><annotation encoding=\"application/x-tex\">\\|\\vec{b}\\| = \\sqrt{b_1^2 + b_2^2 + \\ldots + b_n^2}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.2274399999999999em;vertical-align:-0.25em;\"></span><span class=\"mord\">∥</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9774399999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span></span></span><span style=\"top:-3.26344em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.2355em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z'/></svg></span></span></span></span></span></span></span><span class=\"mord\">∥</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.84em;vertical-align:-0.5413249999999998em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.2986750000000002em;\"><span class=\"svg-align\" style=\"top:-3.8em;\"><span class=\"pstrut\" style=\"height:3.8em;\"></span><span class=\"mord\" style=\"padding-left:1em;\"><span class=\"mord\"><span class=\"mord mathnormal\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7959080000000001em;\"><span style=\"top:-2.433692em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span><span style=\"top:-3.0448000000000004em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.26630799999999993em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7959080000000001em;\"><span style=\"top:-2.433692em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span><span style=\"top:-3.0448000000000004em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.26630799999999993em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"minner\">…</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.740108em;\"><span style=\"top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span><span style=\"top:-2.9890000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3.258675em;\"><span class=\"pstrut\" style=\"height:3.8em;\"></span><span class=\"hide-tail\" style=\"min-width:1.02em;height:1.8800000000000001em;\"><svg width='400em' height='1.8800000000000001em' viewBox='0 0 400000 1944' preserveAspectRatio='xMinYMin slice'><path d='M983 90\nl0 -0\nc4,-6.7,10,-10,18,-10 H400000v40\nH1013.1s-83.4,268,-264.1,840c-180.7,572,-277,876.3,-289,913c-4.7,4.7,-12.7,7,-24,7\ns-12,0,-12,0c-1.3,-3.3,-3.7,-11.7,-7,-25c-35.3,-125.3,-106.7,-373.3,-214,-744\nc-10,12,-21,25,-33,39s-32,39,-32,39c-6,-5.3,-15,-14,-27,-26s25,-30,25,-30\nc26.7,-32.7,52,-63,76,-91s52,-60,52,-60s208,722,208,722\nc56,-175.3,126.3,-397.3,211,-666c84.7,-268.7,153.8,-488.2,207.5,-658.5\nc53.7,-170.3,84.5,-266.8,92.5,-289.5z\nM1001 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.5413249999999998em;\"><span></span></span></span></span></span></span></span></span></span></p>\n<p>例如，余弦相似度可以通过如下方式进行计算和呈现：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np</pre></td></tr><tr><td data-num=\"3\"></td><td><pre></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token comment\"># 创建两个向量</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>a <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>b <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre></pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token comment\"># 计算两个向量的余弦相似度</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>cosine_similarity <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>dot<span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">,</span> b<span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> <span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>linalg<span class=\"token punctuation\">.</span>norm<span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> np<span class=\"token punctuation\">.</span>linalg<span class=\"token punctuation\">.</span>norm<span class=\"token punctuation\">(</span>b<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre></pre></td></tr><tr><td data-num=\"11\"></td><td><pre><span class=\"token comment\"># 绘制向量</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>plt<span class=\"token punctuation\">.</span>quiver<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> a<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> a<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> angles<span class=\"token operator\">=</span><span class=\"token string\">'xy'</span><span class=\"token punctuation\">,</span> scale_units<span class=\"token operator\">=</span><span class=\"token string\">'xy'</span><span class=\"token punctuation\">,</span> scale<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> color<span class=\"token operator\">=</span><span class=\"token string\">'r'</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>plt<span class=\"token punctuation\">.</span>quiver<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> b<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> b<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> angles<span class=\"token operator\">=</span><span class=\"token string\">'xy'</span><span class=\"token punctuation\">,</span> scale_units<span class=\"token operator\">=</span><span class=\"token string\">'xy'</span><span class=\"token punctuation\">,</span> scale<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> color<span class=\"token operator\">=</span><span class=\"token string\">'b'</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre></pre></td></tr><tr><td data-num=\"15\"></td><td><pre><span class=\"token comment\"># 设置图表属性</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>plt<span class=\"token punctuation\">.</span>xlim<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1.5</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>plt<span class=\"token punctuation\">.</span>ylim<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1.5</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>plt<span class=\"token punctuation\">.</span>grid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre>plt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f'Cosine Similarity: </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>cosine_similarity<span class=\"token punctuation\">:</span><span class=\"token format-spec\">.2f</span><span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">'</span></span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>plt<span class=\"token punctuation\">.</span>xlabel<span class=\"token punctuation\">(</span><span class=\"token string\">'X axis'</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>plt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">'Y axis'</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre></pre></td></tr><tr><td data-num=\"23\"></td><td><pre><span class=\"token comment\"># 添加图例</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre>plt<span class=\"token punctuation\">.</span>legend<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token string\">'Vector a'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Vector b'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"25\"></td><td><pre></pre></td></tr><tr><td data-num=\"26\"></td><td><pre><span class=\"token comment\"># 显示图表</span></pre></td></tr><tr><td data-num=\"27\"></td><td><pre>plt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p><img data-src=\"1.RAG%E5%85%A5%E9%97%A8%E4%B8%8E%E4%BB%8E%E9%9B%B6%E5%88%B0%E4%B8%80%E6%90%AD%E5%BB%BARAG%E7%B3%BB%E7%BB%9F%281%29_files/1.RAG%E5%85%A5%E9%97%A8%E4%B8%8E%E4%BB%8E%E9%9B%B6%E5%88%B0%E4%B8%80%E6%90%AD%E5%BB%BARAG%E7%B3%BB%E7%BB%9F%281%29_95_0.png\" alt=\"png\"></p>\n<p>这幅图展示了二维空间中两个向量的方向。红色向量代表<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mover accent=\"true\"><mi>a</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{a}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.2355em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z'/></svg></span></span></span></span></span></span></span></span></span></span> ，蓝色向量代表 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mover accent=\"true\"><mi>b</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{b}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.9774399999999999em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9774399999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span></span></span><span style=\"top:-3.26344em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.2355em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z'/></svg></span></span></span></span></span></span></span></span></span></span>  。它们之间的夹角表示了两个向量的余弦相似度。余弦相似度是通过计算两个向量的点积并除以它们各自的范数（即长度）来得到的。在这个示例中，这两个向量的余弦相似度大约为 0.71，意味着它们在方向上有一定程度的相似性。这个值越接近 1，表示两个向量的方向越相似。</p>\n<ul>\n<li>余弦相似度计算函数</li>\n</ul>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">cosine_sim</span><span class=\"token punctuation\">(</span>vector1<span class=\"token punctuation\">:</span> List<span class=\"token punctuation\">[</span><span class=\"token builtin\">float</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> vector2<span class=\"token punctuation\">:</span> List<span class=\"token punctuation\">[</span><span class=\"token builtin\">float</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> <span class=\"token builtin\">float</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    计算两个向量之间的余弦相似度</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    \"\"\"</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    dot_product <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>dot<span class=\"token punctuation\">(</span>vector1<span class=\"token punctuation\">,</span> vector2<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    magnitude <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>linalg<span class=\"token punctuation\">.</span>norm<span class=\"token punctuation\">(</span>vector1<span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> np<span class=\"token punctuation\">.</span>linalg<span class=\"token punctuation\">.</span>norm<span class=\"token punctuation\">(</span>vector2<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>    <span class=\"token keyword\">if</span> <span class=\"token keyword\">not</span> magnitude<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>        <span class=\"token keyword\">return</span> <span class=\"token number\">0</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>    <span class=\"token keyword\">return</span> dot_product <span class=\"token operator\">/</span> magnitude</pre></td></tr></table></figure><figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>text1 <span class=\"token operator\">=</span> <span class=\"token string\">'我喜欢吃苹果'</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>text2 <span class=\"token operator\">=</span> <span class=\"token string\">\"苹果是我最喜欢吃的水果\"</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>text3 <span class=\"token operator\">=</span> <span class=\"token string\">\"我喜欢用苹果手机\"</span></pre></td></tr></table></figure><figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>vector1 <span class=\"token operator\">=</span> client<span class=\"token punctuation\">.</span>embeddings<span class=\"token punctuation\">.</span>create<span class=\"token punctuation\">(</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    <span class=\"token builtin\">input</span><span class=\"token operator\">=</span>text1<span class=\"token punctuation\">,</span>  </pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    model<span class=\"token operator\">=</span><span class=\"token string\">\"text-embedding-3-large\"</span>  </pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>embedding</pre></td></tr><tr><td data-num=\"5\"></td><td><pre></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>vector2 <span class=\"token operator\">=</span> client<span class=\"token punctuation\">.</span>embeddings<span class=\"token punctuation\">.</span>create<span class=\"token punctuation\">(</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>    <span class=\"token builtin\">input</span><span class=\"token operator\">=</span>text2<span class=\"token punctuation\">,</span>  </pre></td></tr><tr><td data-num=\"8\"></td><td><pre>    model<span class=\"token operator\">=</span><span class=\"token string\">\"text-embedding-3-large\"</span>  </pre></td></tr><tr><td data-num=\"9\"></td><td><pre><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>embedding</pre></td></tr><tr><td data-num=\"10\"></td><td><pre></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>vector3 <span class=\"token operator\">=</span> client<span class=\"token punctuation\">.</span>embeddings<span class=\"token punctuation\">.</span>create<span class=\"token punctuation\">(</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>    <span class=\"token builtin\">input</span><span class=\"token operator\">=</span>text3<span class=\"token punctuation\">,</span>  </pre></td></tr><tr><td data-num=\"13\"></td><td><pre>    model<span class=\"token operator\">=</span><span class=\"token string\">\"text-embedding-3-large\"</span>  </pre></td></tr><tr><td data-num=\"14\"></td><td><pre><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>embedding</pre></td></tr></table></figure><figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>cosine_sim<span class=\"token punctuation\">(</span>vector1<span class=\"token punctuation\">,</span> vector2<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><pre><code>np.float64(0.7661800739633343)\n</code></pre>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>cosine_sim<span class=\"token punctuation\">(</span>vector1<span class=\"token punctuation\">,</span> vector3<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><pre><code>np.float64(0.7224817543294454)\n</code></pre>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>cosine_sim<span class=\"token punctuation\">(</span>vector2<span class=\"token punctuation\">,</span> vector3<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><pre><code>np.float64(0.6315437708887437)\n</code></pre>\n<p>  为了实现 RAG 模型的功能，我们首先需要一个向量化（Embedding）模块。向量化是 RAG 的基础，它的作用是将文档片段转化为向量表示，便于后续的检索操作。在这个过程中，我们将实现一个向量化类，用来将文本片段映射成向量。</p>\n<p>  为了便于扩展和未来可能使用不同的模型，我们首先编写一个 <strong>Embedding 基类</strong>。该基类定义了获取文本向量表示的方法，同时包含一个计算两个向量之间<strong>余弦相似度</strong>的功能。这样，如果我们未来使用不同的向量化模型，只需继承该基类并重写向量获取的逻辑，而不需要重复编写相似度计算部分。</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">class</span> <span class=\"token class-name\">BaseEmbeddings</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    向量化的基类，用于将文本转换为向量表示。不同的子类可以实现不同的向量获取方法。</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    \"\"\"</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> path<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">,</span> is_api<span class=\"token punctuation\">:</span> <span class=\"token builtin\">bool</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>        <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"7\"></td><td><pre>        初始化基类。</pre></td></tr><tr><td data-num=\"8\"></td><td><pre>        </pre></td></tr><tr><td data-num=\"9\"></td><td><pre>        参数：</pre></td></tr><tr><td data-num=\"10\"></td><td><pre>        path (str) - 如果是本地模型，path 表示模型路径；如果是API模式，path可以为空</pre></td></tr><tr><td data-num=\"11\"></td><td><pre>        is_api (bool) - 表示是否使用API调用，如果为True表示通过API获取Embedding</pre></td></tr><tr><td data-num=\"12\"></td><td><pre>        \"\"\"</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>        self<span class=\"token punctuation\">.</span>path <span class=\"token operator\">=</span> path</pre></td></tr><tr><td data-num=\"14\"></td><td><pre>        self<span class=\"token punctuation\">.</span>is_api <span class=\"token operator\">=</span> is_api</pre></td></tr><tr><td data-num=\"15\"></td><td><pre>    </pre></td></tr><tr><td data-num=\"16\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">get_embedding</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> text<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">,</span> model<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> List<span class=\"token punctuation\">[</span><span class=\"token builtin\">float</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>        <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"18\"></td><td><pre>        抽象方法，用于获取文本的向量表示，具体实现需要在子类中定义。</pre></td></tr><tr><td data-num=\"19\"></td><td><pre>        </pre></td></tr><tr><td data-num=\"20\"></td><td><pre>        参数：</pre></td></tr><tr><td data-num=\"21\"></td><td><pre>        text (str) - 需要转换为向量的文本</pre></td></tr><tr><td data-num=\"22\"></td><td><pre>        model (str) - 所使用的模型名称</pre></td></tr><tr><td data-num=\"23\"></td><td><pre>        </pre></td></tr><tr><td data-num=\"24\"></td><td><pre>        返回：</pre></td></tr><tr><td data-num=\"25\"></td><td><pre>        list[float] - 文本的向量表示</pre></td></tr><tr><td data-num=\"26\"></td><td><pre>        \"\"\"</span></pre></td></tr><tr><td data-num=\"27\"></td><td><pre>        <span class=\"token keyword\">raise</span> NotImplementedError</pre></td></tr><tr><td data-num=\"28\"></td><td><pre>    </pre></td></tr><tr><td data-num=\"29\"></td><td><pre>    <span class=\"token decorator annotation punctuation\">@classmethod</span></pre></td></tr><tr><td data-num=\"30\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">cosine_similarity</span><span class=\"token punctuation\">(</span>cls<span class=\"token punctuation\">,</span> vector1<span class=\"token punctuation\">:</span> List<span class=\"token punctuation\">[</span><span class=\"token builtin\">float</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> vector2<span class=\"token punctuation\">:</span> List<span class=\"token punctuation\">[</span><span class=\"token builtin\">float</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> <span class=\"token builtin\">float</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"31\"></td><td><pre>        <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"32\"></td><td><pre>        计算两个向量之间的余弦相似度，用于衡量它们的相似程度。</pre></td></tr><tr><td data-num=\"33\"></td><td><pre>        </pre></td></tr><tr><td data-num=\"34\"></td><td><pre>        参数：</pre></td></tr><tr><td data-num=\"35\"></td><td><pre>        vector1 (list[float]) - 第一个向量</pre></td></tr><tr><td data-num=\"36\"></td><td><pre>        vector2 (list[float]) - 第二个向量</pre></td></tr><tr><td data-num=\"37\"></td><td><pre>        </pre></td></tr><tr><td data-num=\"38\"></td><td><pre>        返回：</pre></td></tr><tr><td data-num=\"39\"></td><td><pre>        float - 余弦相似度值，范围从 -1 到 1，越接近 1 表示向量越相似</pre></td></tr><tr><td data-num=\"40\"></td><td><pre>        \"\"\"</span></pre></td></tr><tr><td data-num=\"41\"></td><td><pre>        dot_product <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>dot<span class=\"token punctuation\">(</span>vector1<span class=\"token punctuation\">,</span> vector2<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 向量点积</span></pre></td></tr><tr><td data-num=\"42\"></td><td><pre>        magnitude <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>linalg<span class=\"token punctuation\">.</span>norm<span class=\"token punctuation\">(</span>vector1<span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> np<span class=\"token punctuation\">.</span>linalg<span class=\"token punctuation\">.</span>norm<span class=\"token punctuation\">(</span>vector2<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 向量的模</span></pre></td></tr><tr><td data-num=\"43\"></td><td><pre>        <span class=\"token keyword\">if</span> <span class=\"token keyword\">not</span> magnitude<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"44\"></td><td><pre>            <span class=\"token keyword\">return</span> <span class=\"token number\">0</span></pre></td></tr><tr><td data-num=\"45\"></td><td><pre>        <span class=\"token keyword\">return</span> dot_product <span class=\"token operator\">/</span> magnitude  <span class=\"token comment\"># 计算余弦相似度</span></pre></td></tr></table></figure><p>我们在这个基类基础上，可以通过继承它来实现具体的模型。例如，我们可以使用 OpenAI 的 API 来生成文本的向量表示，只需重写  <code>get_embedding</code>  方法即可。</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">class</span> <span class=\"token class-name\">OpenAIEmbedding</span><span class=\"token punctuation\">(</span>BaseEmbeddings<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    使用 OpenAI 的 Embedding API 来获取文本向量的类，继承自 BaseEmbeddings。</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    \"\"\"</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> path<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span> <span class=\"token operator\">=</span> <span class=\"token string\">''</span><span class=\"token punctuation\">,</span> is_api<span class=\"token punctuation\">:</span> <span class=\"token builtin\">bool</span> <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>        <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"7\"></td><td><pre>        初始化类，设置 OpenAI API 客户端，如果使用的是 API 调用。</pre></td></tr><tr><td data-num=\"8\"></td><td><pre>        </pre></td></tr><tr><td data-num=\"9\"></td><td><pre>        参数：</pre></td></tr><tr><td data-num=\"10\"></td><td><pre>        path (str) - 本地模型的路径，使用API时可以为空</pre></td></tr><tr><td data-num=\"11\"></td><td><pre>        is_api (bool) - 是否通过 API 获取 Embedding，默认为 True</pre></td></tr><tr><td data-num=\"12\"></td><td><pre>        \"\"\"</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span>path<span class=\"token punctuation\">,</span> is_api<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>        <span class=\"token keyword\">if</span> self<span class=\"token punctuation\">.</span>is_api<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>            <span class=\"token comment\"># 初始化 OpenAI API 客户端</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>            <span class=\"token keyword\">from</span> openai <span class=\"token keyword\">import</span> OpenAI</pre></td></tr><tr><td data-num=\"17\"></td><td><pre>            self<span class=\"token punctuation\">.</span>client <span class=\"token operator\">=</span> OpenAI<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>            self<span class=\"token punctuation\">.</span>client<span class=\"token punctuation\">.</span>api_key <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>getenv<span class=\"token punctuation\">(</span><span class=\"token string\">\"OPENAI_API_KEY\"</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 从环境变量中获取 API 密钥</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre>            self<span class=\"token punctuation\">.</span>client<span class=\"token punctuation\">.</span>base_url <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>getenv<span class=\"token punctuation\">(</span><span class=\"token string\">\"OPENAI_BASE_URL\"</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 从环境变量中获取 API 基础 URL</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>    </pre></td></tr><tr><td data-num=\"21\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">get_embedding</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> text<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">,</span> model<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span> <span class=\"token operator\">=</span> <span class=\"token string\">\"text-embedding-3-large\"</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> List<span class=\"token punctuation\">[</span><span class=\"token builtin\">float</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre>        <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"23\"></td><td><pre>        使用 OpenAI 的 Embedding API 获取文本的向量表示。</pre></td></tr><tr><td data-num=\"24\"></td><td><pre>        </pre></td></tr><tr><td data-num=\"25\"></td><td><pre>        参数：</pre></td></tr><tr><td data-num=\"26\"></td><td><pre>        text (str) - 需要转化为向量的文本</pre></td></tr><tr><td data-num=\"27\"></td><td><pre>        model (str) - 使用的 Embedding 模型名称，默认为 'text-embedding-3-large'</pre></td></tr><tr><td data-num=\"28\"></td><td><pre>        </pre></td></tr><tr><td data-num=\"29\"></td><td><pre>        返回：</pre></td></tr><tr><td data-num=\"30\"></td><td><pre>        list[float] - 文本的向量表示</pre></td></tr><tr><td data-num=\"31\"></td><td><pre>        \"\"\"</span></pre></td></tr><tr><td data-num=\"32\"></td><td><pre>        <span class=\"token keyword\">if</span> self<span class=\"token punctuation\">.</span>is_api<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"33\"></td><td><pre>            <span class=\"token comment\"># 去掉文本中的换行符，保证输入格式规范</span></pre></td></tr><tr><td data-num=\"34\"></td><td><pre>            text <span class=\"token operator\">=</span> text<span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span><span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\" \"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"35\"></td><td><pre>            <span class=\"token comment\"># 调用 OpenAI API 获取文本的向量表示</span></pre></td></tr><tr><td data-num=\"36\"></td><td><pre>            <span class=\"token keyword\">return</span> self<span class=\"token punctuation\">.</span>client<span class=\"token punctuation\">.</span>embeddings<span class=\"token punctuation\">.</span>create<span class=\"token punctuation\">(</span><span class=\"token builtin\">input</span><span class=\"token operator\">=</span><span class=\"token punctuation\">[</span>text<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> model<span class=\"token operator\">=</span>model<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>embedding</pre></td></tr><tr><td data-num=\"37\"></td><td><pre>        <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"38\"></td><td><pre>            <span class=\"token keyword\">raise</span> NotImplementedError  <span class=\"token comment\"># 如果不是 API 模式，这里未实现本地模型的处理</span></pre></td></tr></table></figure><p>这样设计的结构让我们可以轻松替换或扩展向量化模型，而不需要改变整体框架。</p>\n<ul>\n<li>使用示例</li>\n</ul>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 初始化 Embedding 模型</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>embedding_model <span class=\"token operator\">=</span> OpenAIEmbedding<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 输入需要获取向量表示的文本</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>text <span class=\"token operator\">=</span> <span class=\"token string\">\"这是一个示例文本，用于演示 OpenAI Embedding 的使用。\"</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token comment\"># 获取文本的向量表示</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>embedding_vector <span class=\"token operator\">=</span> embedding_model<span class=\"token punctuation\">.</span>get_embedding<span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">,</span> model<span class=\"token operator\">=</span><span class=\"token string\">\"text-embedding-3-large\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre></pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"文本的向量表示为：\"</span><span class=\"token punctuation\">,</span> embedding_vector<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><pre><code>文本的向量表示为： [0.02648121863603592, 0.013051084242761135, -0.007090849336236715, -0.010436945594847202, 0.01947532780468464, 0.013410528190433979, -0.0019606035202741623, 0.03531700372695923, 0.010855208151042461, 0.016273008659482002, -0.020638620480895042,  -0.006090941373258829, -0.028677094727754593, 0.0077574546448886395, -0.011554489843547344, -0.01320139691233635, -0.014848303981125355, -0.008796574547886848]\n</code></pre>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>vector1 <span class=\"token operator\">=</span> embedding_model<span class=\"token punctuation\">.</span>get_embedding<span class=\"token punctuation\">(</span>text1<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>vector2 <span class=\"token operator\">=</span> embedding_model<span class=\"token punctuation\">.</span>get_embedding<span class=\"token punctuation\">(</span>text2<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>similarity <span class=\"token operator\">=</span> BaseEmbeddings<span class=\"token punctuation\">.</span>cosine_similarity<span class=\"token punctuation\">(</span>vector1<span class=\"token punctuation\">,</span> vector2<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"两段文本的余弦相似度为: </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>similarity<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><pre><code>两段文本的余弦相似度为: 0.7661800739633343\n</code></pre>\n<h3 id=\"3-文档加载与切分模块创建\"><a class=\"anchor\" href=\"#3-文档加载与切分模块创建\">#</a> 3. 文档加载与切分模块创建</h3>\n<p>  在实现了向量化之后，我们接下来需要编写一个<strong>文档加载与切分模块</strong>，用于处理不同格式的文档并将其切分为小片段。为什么要进行切分呢？这是为了确保每个文档片段都尽量保持简短且信息集中，以便于后续的向量化和检索。</p>\n<h4 id=\"31-文档格式处理函数\"><a class=\"anchor\" href=\"#31-文档格式处理函数\">#</a> 3.1 文档格式处理函数</h4>\n<p>  我们的目标是支持多种格式的文档，例如 PDF、Markdown、TXT 等。每种文件格式都有不同的读取方式，下面我们展示一个支持多种格式的简单实现：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">read_file_content</span><span class=\"token punctuation\">(</span>cls<span class=\"token punctuation\">,</span> file_path<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    <span class=\"token comment\"># 根据文件扩展名选择读取方法</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    <span class=\"token keyword\">if</span> file_path<span class=\"token punctuation\">.</span>endswith<span class=\"token punctuation\">(</span><span class=\"token string\">'.pdf'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>        <span class=\"token keyword\">return</span> cls<span class=\"token punctuation\">.</span>read_pdf<span class=\"token punctuation\">(</span>file_path<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    <span class=\"token keyword\">elif</span> file_path<span class=\"token punctuation\">.</span>endswith<span class=\"token punctuation\">(</span><span class=\"token string\">'.md'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>        <span class=\"token keyword\">return</span> cls<span class=\"token punctuation\">.</span>read_markdown<span class=\"token punctuation\">(</span>file_path<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>    <span class=\"token keyword\">elif</span> file_path<span class=\"token punctuation\">.</span>endswith<span class=\"token punctuation\">(</span><span class=\"token string\">'.txt'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>        <span class=\"token keyword\">return</span> cls<span class=\"token punctuation\">.</span>read_text<span class=\"token punctuation\">(</span>file_path<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>    <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>        <span class=\"token keyword\">raise</span> ValueError<span class=\"token punctuation\">(</span><span class=\"token string\">\"Unsupported file type\"</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><h4 id=\"32-文档切分函数\"><a class=\"anchor\" href=\"#32-文档切分函数\">#</a> 3.2 文档切分函数</h4>\n<p>  这里我们考虑将文档按<strong> Token</strong> 长度进行切分，设置一个最大的 Token 长度，然后按这个长度进行切分。在这个过程中，我们也会确保每个片段之间有一定的重叠，避免重要信息被切掉。</p>\n<center><center><img data-src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20231218182814731.png\" alt=\"image-20231218182814731\" style=\"zoom:33%;\" /></center> \n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">get_chunk</span><span class=\"token punctuation\">(</span>cls<span class=\"token punctuation\">,</span> text<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">,</span> max_token_len<span class=\"token punctuation\">:</span> <span class=\"token builtin\">int</span> <span class=\"token operator\">=</span> <span class=\"token number\">600</span><span class=\"token punctuation\">,</span> cover_content<span class=\"token punctuation\">:</span> <span class=\"token builtin\">int</span> <span class=\"token operator\">=</span> <span class=\"token number\">150</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    chunk_text <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    curr_len <span class=\"token operator\">=</span> <span class=\"token number\">0</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    curr_chunk <span class=\"token operator\">=</span> <span class=\"token string\">''</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    lines <span class=\"token operator\">=</span> text<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">'\\n'</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 以换行符为单位切分文本</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>    <span class=\"token keyword\">for</span> line <span class=\"token keyword\">in</span> lines<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>        line <span class=\"token operator\">=</span> line<span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span><span class=\"token string\">' '</span><span class=\"token punctuation\">,</span> <span class=\"token string\">''</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>        line_len <span class=\"token operator\">=</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>enc<span class=\"token punctuation\">.</span>encode<span class=\"token punctuation\">(</span>line<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 计算当前行的 Token 长度</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>        <span class=\"token keyword\">if</span> line_len <span class=\"token operator\">></span> max_token_len<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>            <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'warning line_len = '</span><span class=\"token punctuation\">,</span> line_len<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>        <span class=\"token keyword\">if</span> curr_len <span class=\"token operator\">+</span> line_len <span class=\"token operator\">&lt;=</span> max_token_len<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>            curr_chunk <span class=\"token operator\">+=</span> line <span class=\"token operator\">+</span> <span class=\"token string\">'\\n'</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>            curr_len <span class=\"token operator\">+=</span> line_len <span class=\"token operator\">+</span> <span class=\"token number\">1</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>        <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>            chunk_text<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>curr_chunk<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>            curr_chunk <span class=\"token operator\">=</span> curr_chunk<span class=\"token punctuation\">[</span><span class=\"token operator\">-</span>cover_content<span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> line</pre></td></tr><tr><td data-num=\"18\"></td><td><pre>            curr_len <span class=\"token operator\">=</span> line_len <span class=\"token operator\">+</span> cover_content</pre></td></tr><tr><td data-num=\"19\"></td><td><pre></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>    <span class=\"token keyword\">if</span> curr_chunk<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>        chunk_text<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>curr_chunk<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre></pre></td></tr><tr><td data-num=\"23\"></td><td><pre>    <span class=\"token keyword\">return</span> chunk_text</pre></td></tr></table></figure><p>完整类编写如下：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>enc <span class=\"token operator\">=</span> tiktoken<span class=\"token punctuation\">.</span>get_encoding<span class=\"token punctuation\">(</span><span class=\"token string\">\"cl100k_base\"</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>enc<span class=\"token punctuation\">.</span>encode<span class=\"token punctuation\">(</span><span class=\"token string\">\"你好，好久不见！\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><pre><code>9\n</code></pre>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">class</span> <span class=\"token class-name\">ReadFiles</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    读取文件的类，用于从指定路径读取支持的文件类型（如 .txt、.md、.pdf）并进行内容分割。</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    \"\"\"</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> path<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>        <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"8\"></td><td><pre>        初始化函数，设定要读取的文件路径，并获取该路径下所有符合要求的文件。</pre></td></tr><tr><td data-num=\"9\"></td><td><pre>        :param path: 文件夹路径</pre></td></tr><tr><td data-num=\"10\"></td><td><pre>        \"\"\"</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>        self<span class=\"token punctuation\">.</span>_path <span class=\"token operator\">=</span> path</pre></td></tr><tr><td data-num=\"12\"></td><td><pre>        self<span class=\"token punctuation\">.</span>file_list <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>get_files<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 获取文件列表</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">get_files</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>        <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"16\"></td><td><pre>        遍历指定文件夹，获取支持的文件类型列表（txt, md, pdf）。</pre></td></tr><tr><td data-num=\"17\"></td><td><pre>        :return: 文件路径列表</pre></td></tr><tr><td data-num=\"18\"></td><td><pre>        \"\"\"</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre>        file_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>        <span class=\"token keyword\">for</span> filepath<span class=\"token punctuation\">,</span> dirnames<span class=\"token punctuation\">,</span> filenames <span class=\"token keyword\">in</span> os<span class=\"token punctuation\">.</span>walk<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>_path<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>            <span class=\"token comment\"># os.walk 函数将递归遍历指定文件夹</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre>            <span class=\"token keyword\">for</span> filename <span class=\"token keyword\">in</span> filenames<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre>                <span class=\"token comment\"># 根据文件后缀筛选支持的文件类型</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre>                <span class=\"token keyword\">if</span> filename<span class=\"token punctuation\">.</span>endswith<span class=\"token punctuation\">(</span><span class=\"token string\">\".md\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"25\"></td><td><pre>                    file_list<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>filepath<span class=\"token punctuation\">,</span> filename<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"26\"></td><td><pre>                <span class=\"token keyword\">elif</span> filename<span class=\"token punctuation\">.</span>endswith<span class=\"token punctuation\">(</span><span class=\"token string\">\".txt\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"27\"></td><td><pre>                    file_list<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>filepath<span class=\"token punctuation\">,</span> filename<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"28\"></td><td><pre>                <span class=\"token keyword\">elif</span> filename<span class=\"token punctuation\">.</span>endswith<span class=\"token punctuation\">(</span><span class=\"token string\">\".pdf\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"29\"></td><td><pre>                    file_list<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>filepath<span class=\"token punctuation\">,</span> filename<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"30\"></td><td><pre>        <span class=\"token keyword\">return</span> file_list</pre></td></tr><tr><td data-num=\"31\"></td><td><pre></pre></td></tr><tr><td data-num=\"32\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">get_content</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> max_token_len<span class=\"token punctuation\">:</span> <span class=\"token builtin\">int</span> <span class=\"token operator\">=</span> <span class=\"token number\">600</span><span class=\"token punctuation\">,</span> cover_content<span class=\"token punctuation\">:</span> <span class=\"token builtin\">int</span> <span class=\"token operator\">=</span> <span class=\"token number\">150</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"33\"></td><td><pre>        <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"34\"></td><td><pre>        读取文件内容并进行分割，将长文本切分为多个块。</pre></td></tr><tr><td data-num=\"35\"></td><td><pre>        :param max_token_len: 每个文档片段的最大 Token 长度</pre></td></tr><tr><td data-num=\"36\"></td><td><pre>        :param cover_content: 在每个片段之间重叠的 Token 长度</pre></td></tr><tr><td data-num=\"37\"></td><td><pre>        :return: 切分后的文档片段列表</pre></td></tr><tr><td data-num=\"38\"></td><td><pre>        \"\"\"</span></pre></td></tr><tr><td data-num=\"39\"></td><td><pre>        docs <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"40\"></td><td><pre>        <span class=\"token keyword\">for</span> <span class=\"token builtin\">file</span> <span class=\"token keyword\">in</span> self<span class=\"token punctuation\">.</span>file_list<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"41\"></td><td><pre>            content <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>read_file_content<span class=\"token punctuation\">(</span><span class=\"token builtin\">file</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 读取文件内容</span></pre></td></tr><tr><td data-num=\"42\"></td><td><pre>            <span class=\"token comment\"># 分割文档为多个小块</span></pre></td></tr><tr><td data-num=\"43\"></td><td><pre>            chunk_content <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>get_chunk<span class=\"token punctuation\">(</span>content<span class=\"token punctuation\">,</span> max_token_len<span class=\"token operator\">=</span>max_token_len<span class=\"token punctuation\">,</span> cover_content<span class=\"token operator\">=</span>cover_content<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"44\"></td><td><pre>            docs<span class=\"token punctuation\">.</span>extend<span class=\"token punctuation\">(</span>chunk_content<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"45\"></td><td><pre>        <span class=\"token keyword\">return</span> docs</pre></td></tr><tr><td data-num=\"46\"></td><td><pre></pre></td></tr><tr><td data-num=\"47\"></td><td><pre>    <span class=\"token decorator annotation punctuation\">@classmethod</span></pre></td></tr><tr><td data-num=\"48\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">get_chunk</span><span class=\"token punctuation\">(</span>cls<span class=\"token punctuation\">,</span> text<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">,</span> max_token_len<span class=\"token punctuation\">:</span> <span class=\"token builtin\">int</span> <span class=\"token operator\">=</span> <span class=\"token number\">600</span><span class=\"token punctuation\">,</span> cover_content<span class=\"token punctuation\">:</span> <span class=\"token builtin\">int</span> <span class=\"token operator\">=</span> <span class=\"token number\">150</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"49\"></td><td><pre>        <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"50\"></td><td><pre>        将文档内容按最大 Token 长度进行切分。</pre></td></tr><tr><td data-num=\"51\"></td><td><pre>        :param text: 文档内容</pre></td></tr><tr><td data-num=\"52\"></td><td><pre>        :param max_token_len: 每个片段的最大 Token 长度</pre></td></tr><tr><td data-num=\"53\"></td><td><pre>        :param cover_content: 重叠的内容长度</pre></td></tr><tr><td data-num=\"54\"></td><td><pre>        :return: 切分后的文档片段列表</pre></td></tr><tr><td data-num=\"55\"></td><td><pre>        \"\"\"</span></pre></td></tr><tr><td data-num=\"56\"></td><td><pre>        chunk_text <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"57\"></td><td><pre>        curr_len <span class=\"token operator\">=</span> <span class=\"token number\">0</span></pre></td></tr><tr><td data-num=\"58\"></td><td><pre>        curr_chunk <span class=\"token operator\">=</span> <span class=\"token string\">''</span></pre></td></tr><tr><td data-num=\"59\"></td><td><pre>        token_len <span class=\"token operator\">=</span> max_token_len <span class=\"token operator\">-</span> cover_content</pre></td></tr><tr><td data-num=\"60\"></td><td><pre>        lines <span class=\"token operator\">=</span> text<span class=\"token punctuation\">.</span>splitlines<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 以换行符分割文本为行</span></pre></td></tr><tr><td data-num=\"61\"></td><td><pre></pre></td></tr><tr><td data-num=\"62\"></td><td><pre>        <span class=\"token keyword\">for</span> line <span class=\"token keyword\">in</span> lines<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"63\"></td><td><pre>            line <span class=\"token operator\">=</span> line<span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span><span class=\"token string\">' '</span><span class=\"token punctuation\">,</span> <span class=\"token string\">''</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 去除空格</span></pre></td></tr><tr><td data-num=\"64\"></td><td><pre>            line_len <span class=\"token operator\">=</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>enc<span class=\"token punctuation\">.</span>encode<span class=\"token punctuation\">(</span>line<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 计算当前行的 Token 长度</span></pre></td></tr><tr><td data-num=\"65\"></td><td><pre>            <span class=\"token keyword\">if</span> line_len <span class=\"token operator\">></span> max_token_len<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"66\"></td><td><pre>                <span class=\"token comment\"># 如果单行长度超过限制，将其分割为多个片段</span></pre></td></tr><tr><td data-num=\"67\"></td><td><pre>                num_chunks <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>line_len <span class=\"token operator\">+</span> token_len <span class=\"token operator\">-</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">//</span> token_len</pre></td></tr><tr><td data-num=\"68\"></td><td><pre>                <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>num_chunks<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"69\"></td><td><pre>                    start <span class=\"token operator\">=</span> i <span class=\"token operator\">*</span> token_len</pre></td></tr><tr><td data-num=\"70\"></td><td><pre>                    end <span class=\"token operator\">=</span> start <span class=\"token operator\">+</span> token_len</pre></td></tr><tr><td data-num=\"71\"></td><td><pre>                    <span class=\"token comment\"># 防止跨单词分割</span></pre></td></tr><tr><td data-num=\"72\"></td><td><pre>                    <span class=\"token keyword\">while</span> <span class=\"token keyword\">not</span> line<span class=\"token punctuation\">[</span>start<span class=\"token punctuation\">:</span>end<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>rstrip<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>isspace<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"73\"></td><td><pre>                        start <span class=\"token operator\">+=</span> <span class=\"token number\">1</span></pre></td></tr><tr><td data-num=\"74\"></td><td><pre>                        end <span class=\"token operator\">+=</span> <span class=\"token number\">1</span></pre></td></tr><tr><td data-num=\"75\"></td><td><pre>                        <span class=\"token keyword\">if</span> start <span class=\"token operator\">>=</span> line_len<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"76\"></td><td><pre>                            <span class=\"token keyword\">break</span></pre></td></tr><tr><td data-num=\"77\"></td><td><pre>                    curr_chunk <span class=\"token operator\">=</span> curr_chunk<span class=\"token punctuation\">[</span><span class=\"token operator\">-</span>cover_content<span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> line<span class=\"token punctuation\">[</span>start<span class=\"token punctuation\">:</span>end<span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"78\"></td><td><pre>                    chunk_text<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>curr_chunk<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"79\"></td><td><pre>                start <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>num_chunks <span class=\"token operator\">-</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> token_len</pre></td></tr><tr><td data-num=\"80\"></td><td><pre>                curr_chunk <span class=\"token operator\">=</span> curr_chunk<span class=\"token punctuation\">[</span><span class=\"token operator\">-</span>cover_content<span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> line<span class=\"token punctuation\">[</span>start<span class=\"token punctuation\">:</span>end<span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"81\"></td><td><pre>                chunk_text<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>curr_chunk<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"82\"></td><td><pre>            <span class=\"token keyword\">elif</span> curr_len <span class=\"token operator\">+</span> line_len <span class=\"token operator\">&lt;=</span> token_len<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"83\"></td><td><pre>                <span class=\"token comment\"># 当前片段长度未超过限制时，继续累加</span></pre></td></tr><tr><td data-num=\"84\"></td><td><pre>                curr_chunk <span class=\"token operator\">+=</span> line <span class=\"token operator\">+</span> <span class=\"token string\">'\\n'</span></pre></td></tr><tr><td data-num=\"85\"></td><td><pre>                curr_len <span class=\"token operator\">+=</span> line_len <span class=\"token operator\">+</span> <span class=\"token number\">1</span></pre></td></tr><tr><td data-num=\"86\"></td><td><pre>            <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"87\"></td><td><pre>                chunk_text<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>curr_chunk<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 保存当前片段</span></pre></td></tr><tr><td data-num=\"88\"></td><td><pre>                curr_chunk <span class=\"token operator\">=</span> curr_chunk<span class=\"token punctuation\">[</span><span class=\"token operator\">-</span>cover_content<span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> line</pre></td></tr><tr><td data-num=\"89\"></td><td><pre>                curr_len <span class=\"token operator\">=</span> line_len <span class=\"token operator\">+</span> cover_content</pre></td></tr><tr><td data-num=\"90\"></td><td><pre></pre></td></tr><tr><td data-num=\"91\"></td><td><pre>        <span class=\"token keyword\">if</span> curr_chunk<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"92\"></td><td><pre>            chunk_text<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>curr_chunk<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"93\"></td><td><pre></pre></td></tr><tr><td data-num=\"94\"></td><td><pre>        <span class=\"token keyword\">return</span> chunk_text</pre></td></tr><tr><td data-num=\"95\"></td><td><pre></pre></td></tr><tr><td data-num=\"96\"></td><td><pre>    <span class=\"token decorator annotation punctuation\">@classmethod</span></pre></td></tr><tr><td data-num=\"97\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">read_file_content</span><span class=\"token punctuation\">(</span>cls<span class=\"token punctuation\">,</span> file_path<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"98\"></td><td><pre>        <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"99\"></td><td><pre>        读取文件内容，根据文件类型选择不同的读取方式。</pre></td></tr><tr><td data-num=\"100\"></td><td><pre>        :param file_path: 文件路径</pre></td></tr><tr><td data-num=\"101\"></td><td><pre>        :return: 文件内容</pre></td></tr><tr><td data-num=\"102\"></td><td><pre>        \"\"\"</span></pre></td></tr><tr><td data-num=\"103\"></td><td><pre>        <span class=\"token keyword\">if</span> file_path<span class=\"token punctuation\">.</span>endswith<span class=\"token punctuation\">(</span><span class=\"token string\">'.pdf'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"104\"></td><td><pre>            <span class=\"token keyword\">return</span> cls<span class=\"token punctuation\">.</span>read_pdf<span class=\"token punctuation\">(</span>file_path<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"105\"></td><td><pre>        <span class=\"token keyword\">elif</span> file_path<span class=\"token punctuation\">.</span>endswith<span class=\"token punctuation\">(</span><span class=\"token string\">'.md'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"106\"></td><td><pre>            <span class=\"token keyword\">return</span> cls<span class=\"token punctuation\">.</span>read_markdown<span class=\"token punctuation\">(</span>file_path<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"107\"></td><td><pre>        <span class=\"token keyword\">elif</span> file_path<span class=\"token punctuation\">.</span>endswith<span class=\"token punctuation\">(</span><span class=\"token string\">'.txt'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"108\"></td><td><pre>            <span class=\"token keyword\">return</span> cls<span class=\"token punctuation\">.</span>read_text<span class=\"token punctuation\">(</span>file_path<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"109\"></td><td><pre>        <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"110\"></td><td><pre>            <span class=\"token keyword\">raise</span> ValueError<span class=\"token punctuation\">(</span><span class=\"token string\">\"Unsupported file type\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"111\"></td><td><pre></pre></td></tr><tr><td data-num=\"112\"></td><td><pre>    <span class=\"token decorator annotation punctuation\">@classmethod</span></pre></td></tr><tr><td data-num=\"113\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">read_pdf</span><span class=\"token punctuation\">(</span>cls<span class=\"token punctuation\">,</span> file_path<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"114\"></td><td><pre>        <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"115\"></td><td><pre>        读取 PDF 文件内容。</pre></td></tr><tr><td data-num=\"116\"></td><td><pre>        :param file_path: PDF 文件路径</pre></td></tr><tr><td data-num=\"117\"></td><td><pre>        :return: PDF 文件中的文本内容</pre></td></tr><tr><td data-num=\"118\"></td><td><pre>        \"\"\"</span></pre></td></tr><tr><td data-num=\"119\"></td><td><pre>        <span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span>file_path<span class=\"token punctuation\">,</span> <span class=\"token string\">'rb'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> <span class=\"token builtin\">file</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"120\"></td><td><pre>            reader <span class=\"token operator\">=</span> PyPDF2<span class=\"token punctuation\">.</span>PdfReader<span class=\"token punctuation\">(</span><span class=\"token builtin\">file</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"121\"></td><td><pre>            text <span class=\"token operator\">=</span> <span class=\"token string\">\"\"</span></pre></td></tr><tr><td data-num=\"122\"></td><td><pre>            <span class=\"token keyword\">for</span> page_num <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>reader<span class=\"token punctuation\">.</span>pages<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"123\"></td><td><pre>                text <span class=\"token operator\">+=</span> reader<span class=\"token punctuation\">.</span>pages<span class=\"token punctuation\">[</span>page_num<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>extract_text<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"124\"></td><td><pre>            <span class=\"token keyword\">return</span> text</pre></td></tr><tr><td data-num=\"125\"></td><td><pre></pre></td></tr><tr><td data-num=\"126\"></td><td><pre>    <span class=\"token decorator annotation punctuation\">@classmethod</span></pre></td></tr><tr><td data-num=\"127\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">read_markdown</span><span class=\"token punctuation\">(</span>cls<span class=\"token punctuation\">,</span> file_path<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"128\"></td><td><pre>        <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"129\"></td><td><pre>        读取 Markdown 文件内容，并将其转换为纯文本。</pre></td></tr><tr><td data-num=\"130\"></td><td><pre>        :param file_path: Markdown 文件路径</pre></td></tr><tr><td data-num=\"131\"></td><td><pre>        :return: 纯文本内容</pre></td></tr><tr><td data-num=\"132\"></td><td><pre>        \"\"\"</span></pre></td></tr><tr><td data-num=\"133\"></td><td><pre>        <span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span>file_path<span class=\"token punctuation\">,</span> <span class=\"token string\">'r'</span><span class=\"token punctuation\">,</span> encoding<span class=\"token operator\">=</span><span class=\"token string\">'utf-8'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> <span class=\"token builtin\">file</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"134\"></td><td><pre>            md_text <span class=\"token operator\">=</span> <span class=\"token builtin\">file</span><span class=\"token punctuation\">.</span>read<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"135\"></td><td><pre>            html_text <span class=\"token operator\">=</span> markdown<span class=\"token punctuation\">.</span>markdown<span class=\"token punctuation\">(</span>md_text<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"136\"></td><td><pre>            <span class=\"token comment\"># 使用 BeautifulSoup 从 HTML 中提取纯文本</span></pre></td></tr><tr><td data-num=\"137\"></td><td><pre>            soup <span class=\"token operator\">=</span> BeautifulSoup<span class=\"token punctuation\">(</span>html_text<span class=\"token punctuation\">,</span> <span class=\"token string\">'html.parser'</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"138\"></td><td><pre>            plain_text <span class=\"token operator\">=</span> soup<span class=\"token punctuation\">.</span>get_text<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"139\"></td><td><pre>            <span class=\"token comment\"># 使用正则表达式移除网址链接</span></pre></td></tr><tr><td data-num=\"140\"></td><td><pre>            text <span class=\"token operator\">=</span> re<span class=\"token punctuation\">.</span>sub<span class=\"token punctuation\">(</span><span class=\"token string\">r'http\\S+'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">''</span><span class=\"token punctuation\">,</span> plain_text<span class=\"token punctuation\">)</span> </pre></td></tr><tr><td data-num=\"141\"></td><td><pre>            <span class=\"token keyword\">return</span> text</pre></td></tr><tr><td data-num=\"142\"></td><td><pre></pre></td></tr><tr><td data-num=\"143\"></td><td><pre>    <span class=\"token decorator annotation punctuation\">@classmethod</span></pre></td></tr><tr><td data-num=\"144\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">read_text</span><span class=\"token punctuation\">(</span>cls<span class=\"token punctuation\">,</span> file_path<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"145\"></td><td><pre>        <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"146\"></td><td><pre>        读取普通文本文件内容。</pre></td></tr><tr><td data-num=\"147\"></td><td><pre>        :param file_path: 文本文件路径</pre></td></tr><tr><td data-num=\"148\"></td><td><pre>        :return: 文件内容</pre></td></tr><tr><td data-num=\"149\"></td><td><pre>        \"\"\"</span></pre></td></tr><tr><td data-num=\"150\"></td><td><pre>        <span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span>file_path<span class=\"token punctuation\">,</span> <span class=\"token string\">'r'</span><span class=\"token punctuation\">,</span> encoding<span class=\"token operator\">=</span><span class=\"token string\">'utf-8'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> <span class=\"token builtin\">file</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"151\"></td><td><pre>            <span class=\"token keyword\">return</span> <span class=\"token builtin\">file</span><span class=\"token punctuation\">.</span>read<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">class</span> <span class=\"token class-name\">Documents</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    文档类，用于读取已分好类的 JSON 格式文档。</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    \"\"\"</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> path<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span> <span class=\"token operator\">=</span> <span class=\"token string\">''</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>        self<span class=\"token punctuation\">.</span>path <span class=\"token operator\">=</span> path</pre></td></tr><tr><td data-num=\"7\"></td><td><pre></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">get_content</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>        <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"10\"></td><td><pre>        读取 JSON 格式的文档内容。</pre></td></tr><tr><td data-num=\"11\"></td><td><pre>        :return: JSON 文档的内容</pre></td></tr><tr><td data-num=\"12\"></td><td><pre>        \"\"\"</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>        <span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">,</span> mode<span class=\"token operator\">=</span><span class=\"token string\">'r'</span><span class=\"token punctuation\">,</span> encoding<span class=\"token operator\">=</span><span class=\"token string\">'utf-8'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> f<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>            content <span class=\"token operator\">=</span> json<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span>f<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>        <span class=\"token keyword\">return</span> content</pre></td></tr></table></figure><figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 初始化 ReadFiles 类，指定文件目录路径</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>file_reader <span class=\"token operator\">=</span> ReadFiles<span class=\"token punctuation\">(</span>path<span class=\"token operator\">=</span><span class=\"token string\">\"./data\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token comment\"># 获取目录下所有支持的文件类型</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>file_list <span class=\"token operator\">=</span> file_reader<span class=\"token punctuation\">.</span>get_files<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"支持的文件列表：\"</span><span class=\"token punctuation\">,</span> file_list<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><pre><code>支持的文件列表： ['./data/虚拟环境配置方法.md']\n</code></pre>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 将文件内容读取并分块</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>document_chunks <span class=\"token operator\">=</span> file_reader<span class=\"token punctuation\">.</span>get_content<span class=\"token punctuation\">(</span>max_token_len<span class=\"token operator\">=</span><span class=\"token number\">600</span><span class=\"token punctuation\">,</span> cover_content<span class=\"token operator\">=</span><span class=\"token number\">150</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"分块后的文档内容：\"</span><span class=\"token punctuation\">,</span> document_chunks<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><pre><code>分块后的文档内容： [&quot;在Windows上使用Anaconda和JupyterLab配置Python虚拟环境\\n在本教程中，我们将介绍如何在Windows操作系统上，使用Anaconda创建一个Python虚拟环境，并在该环境中安装特定版本的Python和OpenAI库。我们还将展示如何将该环境配置为JupyterLab的一个Kernel，以便在不同项目间切换不同的开发环境。\\n准备工作\\n确保你的Windows系统中已经安装了Anaconda。此外，你还需要安装JupyterLab，如果尚未安装，可以通过AnacondaNavigator或使用conda命令行工具进行安装。\\n创建虚拟环境\\n\\n\\n打开AnacondaPrompt\\n从开始菜单中找到并启动AnacondaPrompt。\\n\\n\\n创建新的虚拟环境\\n使用以下命令创建一个名为openenv的新虚拟环境，其中安装了Python3.8：\\n\\n\\nbash\\ncondacreate-nopenenvpython=3.8\\n\\n激活虚拟环境\\n创建虚拟环境后，使用以下命令激活它：\\n\\nbash\\ncondaactivateopenenv\\n安装所需库\\n在虚拟环境中，安装特定版本的OpenAI库。\\n\\n安装OpenAI0.28.1\\n在激活的虚拟环境中，使用以下命令安装OpenAI0.28，以及其他需要安装的库。这里需要注意的是，目前安装OpenAI0.28版本的库需要提前设置代理，代理设置方法如下：\\n\\nbash\\n#以下'YOUR_PROXY_PORT'需要自己代理的端口号\\nsetHTTP_PROXY=\\nsetHTTPS_PROXY=\\n&quot;, '虚拟环境中，使用以下命令安装OpenAI0.28，以及其他需要安装的库。这里需要注意的是，目前安装OpenAI0.28版本的库需要提前设置代理，代理设置方法如下：\\n\\nbash\\n#以下\\'YOUR_PROXY_PORT\\'需要自己代理的端口号\\nsetHTTP_PROXY=\\nsetHTTPS_PROXY=\\n然后再执行以下安装过程：bash\\npipinstallopenai==0.28.1\\npipinstallmatplotlib,seaborn,tiktoken,pymysql,google-api-python-client,google_auth_oauthlib,bs4,pydrive,cryptography\\n配置JupyterKernel\\n为了在JupyterLab中使用新的虚拟环境，你需要将其添加为一个新的Kernel。\\n\\n\\n安装IPythonKernel\\n在虚拟环境中安装IPythonkernel：\\nbash\\npipinstallipykernel\\n\\n\\n添加环境到Jupyter的Kernel列表\\n将这个虚拟环境添加到Jupyter的Kernel列表中：\\n\\n\\nbash\\npython-mipykernelinstall--user--nameopenenv--display-name&quot;openenv&quot;\\n使用JupyterLab\\n\\n启动JupyterLab\\n你可以在任何地方启动JupyterLab：\\n\\nbash\\njupyterlab\\n\\n在JupyterLab中选择虚拟环境的Kernel\\n打开一个新的notebook，然后在右上角的Kernel选项中选择“Python(myenv)”Kernel。现在，你的notebook将在你的虚拟环境中运行。\\n\\n结束工作\\n完成工作后，记得退出虚拟环境：\\n', 'b：\\n\\nbash\\njupyterlab\\n\\n在JupyterLab中选择虚拟环境的Kernel\\n打开一个新的notebook，然后在右上角的Kernel选项中选择“Python(myenv)”Kernel。现在，你的notebook将在你的虚拟环境中运行。\\n\\n结束工作\\n完成工作后，记得退出虚拟环境：\\nbashcondadeactivate\\n']\n</code></pre>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>document_chunks<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span></pre></td></tr></table></figure><pre><code>&quot;在Windows上使用Anaconda和JupyterLab配置Python虚拟环境\\n在本教程中，我们将介绍如何在Windows操作系统上，使用Anaconda创建一个Python虚拟环境，并在该环境中安装特定版本的Python和OpenAI库。我们还将展示如何将该环境配置为JupyterLab的一个Kernel，以便在不同项目间切换不同的开发环境。\\n准备工作\\n确保你的Windows系统中已经安装了Anaconda。此外，你还需要安装JupyterLab，如果尚未安装，可以通过AnacondaNavigator或使用conda命令行工具进行安装。\\n创建虚拟环境\\n\\n\\n打开AnacondaPrompt\\n从开始菜单中找到并启动AnacondaPrompt。\\n\\n\\n创建新的虚拟环境\\n使用以下命令创建一个名为openenv的新虚拟环境，其中安装了Python3.8：\\n\\n\\nbash\\ncondacreate-nopenenvpython=3.8\\n\\n激活虚拟环境\\n创建虚拟环境后，使用以下命令激活它：\\n\\nbash\\ncondaactivateopenenv\\n安装所需库\\n在虚拟环境中，安装特定版本的OpenAI库。\\n\\n安装OpenAI0.28.1\\n在激活的虚拟环境中，使用以下命令安装OpenAI0.28，以及其他需要安装的库。这里需要注意的是，目前安装OpenAI0.28版本的库需要提前设置代理，代理设置方法如下：\\n\\nbash\\n#以下'YOUR_PROXY_PORT'需要自己代理的端口号\\nsetHTTP_PROXY=\\nsetHTTPS_PROXY=\\n&quot;\n</code></pre>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>document_chunks<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span></pre></td></tr></table></figure><pre><code>'虚拟环境中，使用以下命令安装OpenAI0.28，以及其他需要安装的库。这里需要注意的是，目前安装OpenAI0.28版本的库需要提前设置代理，代理设置方法如下：\\n\\nbash\\n#以下\\'YOUR_PROXY_PORT\\'需要自己代理的端口号\\nsetHTTP_PROXY=\\nsetHTTPS_PROXY=\\n然后再执行以下安装过程：bash\\npipinstallopenai==0.28.1\\npipinstallmatplotlib,seaborn,tiktoken,pymysql,google-api-python-client,google_auth_oauthlib,bs4,pydrive,cryptography\\n配置JupyterKernel\\n为了在JupyterLab中使用新的虚拟环境，你需要将其添加为一个新的Kernel。\\n\\n\\n安装IPythonKernel\\n在虚拟环境中安装IPythonkernel：\\nbash\\npipinstallipykernel\\n\\n\\n添加环境到Jupyter的Kernel列表\\n将这个虚拟环境添加到Jupyter的Kernel列表中：\\n\\n\\nbash\\npython-mipykernelinstall--user--nameopenenv--display-name&quot;openenv&quot;\\n使用JupyterLab\\n\\n启动JupyterLab\\n你可以在任何地方启动JupyterLab：\\n\\nbash\\njupyterlab\\n\\n在JupyterLab中选择虚拟环境的Kernel\\n打开一个新的notebook，然后在右上角的Kernel选项中选择“Python(myenv)”Kernel。现在，你的notebook将在你的虚拟环境中运行。\\n\\n结束工作\\n完成工作后，记得退出虚拟环境：\\n'\n</code></pre>\n<h3 id=\"4-词向量数据库与向量检索模块\"><a class=\"anchor\" href=\"#4-词向量数据库与向量检索模块\">#</a> 4. 词向量数据库与向量检索模块</h3>\n<p>  接下来我们将继续构建<strong>向量数据库</strong>以及<strong>检索模块</strong>，这是 RAG 模型中的核心功能之一。向量数据库用于存储文档片段及其对应的向量表示，而检索模块则根据用户提出的问题（Query）在数据库中检索相关的文档片段。通过这些功能，我们创建的简易 RAG 能够根据输入的查询快速找到最相关的文档片段。</p>\n<p>  为了构建这个向量数据库，我们需要以下几个关键功能：</p>\n<ol>\n<li><strong>持久化存储（persist）：</strong> 将数据库存储到本地，便于下次加载使用。</li>\n<li><strong>加载数据库（load_vector）：</strong> 从本地文件加载已经存储的向量和文档。</li>\n<li><strong>获取向量表示（get_vector）：</strong> 将文档转化为向量表示并存储。</li>\n<li><strong>检索（query）：</strong> 根据用户的 Query，检索数据库中的相关文档片段。</li>\n</ol>\n<p>我们将基于这些功能来实现一个简单的  <code>VectorStore</code>  类。</p>\n<p>  首先，我们创建一个基础的  <code>VectorStore</code>  类，提供上述功能的框架。通过这个类，我们能够将文档片段转化为向量存储，加载本地数据库，进行检索。</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">class</span> <span class=\"token class-name\">VectorStore</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> document<span class=\"token punctuation\">:</span> List<span class=\"token punctuation\">[</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>        <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>        初始化向量存储类，存储文档和对应的向量表示。</pre></td></tr><tr><td data-num=\"5\"></td><td><pre>        :param document: 文档列表，默认为空。</pre></td></tr><tr><td data-num=\"6\"></td><td><pre>        \"\"\"</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>        <span class=\"token keyword\">if</span> document <span class=\"token keyword\">is</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>            document <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>        self<span class=\"token punctuation\">.</span>document <span class=\"token operator\">=</span> document  <span class=\"token comment\"># 存储文档内容</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>        self<span class=\"token punctuation\">.</span>vectors <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>  <span class=\"token comment\"># 存储文档的向量表示</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>    </pre></td></tr><tr><td data-num=\"12\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">get_vector</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> EmbeddingModel<span class=\"token punctuation\">:</span> BaseEmbeddings<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> List<span class=\"token punctuation\">[</span>List<span class=\"token punctuation\">[</span><span class=\"token builtin\">float</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>        <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"14\"></td><td><pre>        使用传入的 Embedding 模型将文档向量化。</pre></td></tr><tr><td data-num=\"15\"></td><td><pre>        :param EmbeddingModel: 传入的用于生成向量的模型（需继承 BaseEmbeddings 类）。</pre></td></tr><tr><td data-num=\"16\"></td><td><pre>        :return: 返回文档对应的向量列表。</pre></td></tr><tr><td data-num=\"17\"></td><td><pre>        \"\"\"</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>        <span class=\"token comment\"># 遍历所有文档，获取每个文档的向量表示</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre>        self<span class=\"token punctuation\">.</span>vectors <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>EmbeddingModel<span class=\"token punctuation\">.</span>get_embedding<span class=\"token punctuation\">(</span>doc<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> doc <span class=\"token keyword\">in</span> self<span class=\"token punctuation\">.</span>document<span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>        <span class=\"token keyword\">return</span> self<span class=\"token punctuation\">.</span>vectors</pre></td></tr><tr><td data-num=\"21\"></td><td><pre>    </pre></td></tr><tr><td data-num=\"22\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">persist</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> path<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span> <span class=\"token operator\">=</span> <span class=\"token string\">'storage'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre>        <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"24\"></td><td><pre>        将文档和对应的向量表示持久化到本地目录中，以便后续加载使用。</pre></td></tr><tr><td data-num=\"25\"></td><td><pre>        :param path: 存储路径，默认为 'storage'。</pre></td></tr><tr><td data-num=\"26\"></td><td><pre>        \"\"\"</span></pre></td></tr><tr><td data-num=\"27\"></td><td><pre>        <span class=\"token keyword\">if</span> <span class=\"token keyword\">not</span> os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>exists<span class=\"token punctuation\">(</span>path<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"28\"></td><td><pre>            os<span class=\"token punctuation\">.</span>makedirs<span class=\"token punctuation\">(</span>path<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 如果路径不存在，创建路径</span></pre></td></tr><tr><td data-num=\"29\"></td><td><pre>        <span class=\"token comment\"># 保存向量为 numpy 文件</span></pre></td></tr><tr><td data-num=\"30\"></td><td><pre>        np<span class=\"token punctuation\">.</span>save<span class=\"token punctuation\">(</span>os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>path<span class=\"token punctuation\">,</span> <span class=\"token string\">'vectors.npy'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>vectors<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"31\"></td><td><pre>        <span class=\"token comment\"># 将文档内容存储到文本文件中</span></pre></td></tr><tr><td data-num=\"32\"></td><td><pre>        <span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span>os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>path<span class=\"token punctuation\">,</span> <span class=\"token string\">'documents.txt'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'w'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> f<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"33\"></td><td><pre>            <span class=\"token keyword\">for</span> doc <span class=\"token keyword\">in</span> self<span class=\"token punctuation\">.</span>document<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"34\"></td><td><pre>                f<span class=\"token punctuation\">.</span>write<span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"</span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>doc<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">\\n\"</span></span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"35\"></td><td><pre>    </pre></td></tr><tr><td data-num=\"36\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">load_vector</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> path<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span> <span class=\"token operator\">=</span> <span class=\"token string\">'storage'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"37\"></td><td><pre>        <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"38\"></td><td><pre>        从本地加载之前保存的文档和向量数据。</pre></td></tr><tr><td data-num=\"39\"></td><td><pre>        :param path: 存储路径，默认为 'storage'。</pre></td></tr><tr><td data-num=\"40\"></td><td><pre>        \"\"\"</span></pre></td></tr><tr><td data-num=\"41\"></td><td><pre>        <span class=\"token comment\"># 加载保存的向量数据</span></pre></td></tr><tr><td data-num=\"42\"></td><td><pre>        self<span class=\"token punctuation\">.</span>vectors <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span>os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>path<span class=\"token punctuation\">,</span> <span class=\"token string\">'vectors.npy'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>tolist<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"43\"></td><td><pre>        <span class=\"token comment\"># 加载文档内容</span></pre></td></tr><tr><td data-num=\"44\"></td><td><pre>        <span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span>os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>path<span class=\"token punctuation\">,</span> <span class=\"token string\">'documents.txt'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'r'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> f<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"45\"></td><td><pre>            self<span class=\"token punctuation\">.</span>document <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>line<span class=\"token punctuation\">.</span>strip<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> line <span class=\"token keyword\">in</span> f<span class=\"token punctuation\">.</span>readlines<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"46\"></td><td><pre></pre></td></tr><tr><td data-num=\"47\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">get_similarity</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> vector1<span class=\"token punctuation\">:</span> List<span class=\"token punctuation\">[</span><span class=\"token builtin\">float</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> vector2<span class=\"token punctuation\">:</span> List<span class=\"token punctuation\">[</span><span class=\"token builtin\">float</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> <span class=\"token builtin\">float</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"48\"></td><td><pre>        <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"49\"></td><td><pre>        计算两个向量的余弦相似度。</pre></td></tr><tr><td data-num=\"50\"></td><td><pre>        :param vector1: 第一个向量。</pre></td></tr><tr><td data-num=\"51\"></td><td><pre>        :param vector2: 第二个向量。</pre></td></tr><tr><td data-num=\"52\"></td><td><pre>        :return: 返回两个向量的余弦相似度，范围从 -1 到 1。</pre></td></tr><tr><td data-num=\"53\"></td><td><pre>        \"\"\"</span></pre></td></tr><tr><td data-num=\"54\"></td><td><pre>        dot_product <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>dot<span class=\"token punctuation\">(</span>vector1<span class=\"token punctuation\">,</span> vector2<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"55\"></td><td><pre>        magnitude <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>linalg<span class=\"token punctuation\">.</span>norm<span class=\"token punctuation\">(</span>vector1<span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> np<span class=\"token punctuation\">.</span>linalg<span class=\"token punctuation\">.</span>norm<span class=\"token punctuation\">(</span>vector2<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"56\"></td><td><pre>        <span class=\"token keyword\">if</span> <span class=\"token keyword\">not</span> magnitude<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"57\"></td><td><pre>            <span class=\"token keyword\">return</span> <span class=\"token number\">0</span></pre></td></tr><tr><td data-num=\"58\"></td><td><pre>        <span class=\"token keyword\">return</span> dot_product <span class=\"token operator\">/</span> magnitude</pre></td></tr><tr><td data-num=\"59\"></td><td><pre></pre></td></tr><tr><td data-num=\"60\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">query</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> query<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">,</span> EmbeddingModel<span class=\"token punctuation\">:</span> BaseEmbeddings<span class=\"token punctuation\">,</span> k<span class=\"token punctuation\">:</span> <span class=\"token builtin\">int</span> <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> List<span class=\"token punctuation\">[</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"61\"></td><td><pre>        <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"62\"></td><td><pre>        根据用户的查询文本，检索最相关的文档片段。</pre></td></tr><tr><td data-num=\"63\"></td><td><pre>        :param query: 用户的查询文本。</pre></td></tr><tr><td data-num=\"64\"></td><td><pre>        :param EmbeddingModel: 用于将查询向量化的嵌入模型。</pre></td></tr><tr><td data-num=\"65\"></td><td><pre>        :param k: 返回最相似的文档数量，默认为 1。</pre></td></tr><tr><td data-num=\"66\"></td><td><pre>        :return: 返回最相似的文档列表。</pre></td></tr><tr><td data-num=\"67\"></td><td><pre>        \"\"\"</span></pre></td></tr><tr><td data-num=\"68\"></td><td><pre>        <span class=\"token comment\"># 将查询文本向量化</span></pre></td></tr><tr><td data-num=\"69\"></td><td><pre>        query_vector <span class=\"token operator\">=</span> EmbeddingModel<span class=\"token punctuation\">.</span>get_embedding<span class=\"token punctuation\">(</span>query<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"70\"></td><td><pre>        <span class=\"token comment\"># 计算查询向量与每个文档向量的相似度</span></pre></td></tr><tr><td data-num=\"71\"></td><td><pre>        similarities <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>self<span class=\"token punctuation\">.</span>get_similarity<span class=\"token punctuation\">(</span>query_vector<span class=\"token punctuation\">,</span> vector<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> vector <span class=\"token keyword\">in</span> self<span class=\"token punctuation\">.</span>vectors<span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"72\"></td><td><pre>        <span class=\"token comment\"># 获取相似度最高的 k 个文档索引</span></pre></td></tr><tr><td data-num=\"73\"></td><td><pre>        top_k_indices <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>argsort<span class=\"token punctuation\">(</span>similarities<span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token operator\">-</span>k<span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">:</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"74\"></td><td><pre>        <span class=\"token comment\"># 返回对应的文档内容</span></pre></td></tr><tr><td data-num=\"75\"></td><td><pre>        <span class=\"token keyword\">return</span> <span class=\"token punctuation\">[</span>self<span class=\"token punctuation\">.</span>document<span class=\"token punctuation\">[</span>idx<span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> idx <span class=\"token keyword\">in</span> top_k_indices<span class=\"token punctuation\">]</span></pre></td></tr></table></figure><p>上述代码解释如下：</p>\n<ul>\n<li><strong>get_vector 方法：</strong> 这个方法使用传入的  <code>EmbeddingModel</code>  对所有文档进行向量化，并将这些向量存储在  <code>self.vectors</code>  中。</li>\n<li><strong>persist 方法：</strong> 该方法将文档片段及其向量表示保存到本地文件系统，便于持久化存储。</li>\n<li><strong>load_vector 方法：</strong> 从本地文件系统加载已保存的文档片段和向量，供后续检索使用。</li>\n<li><strong>get_similarity 方法：</strong> 计算两个向量之间的余弦相似度，用于比较查询和文档向量的相似度。</li>\n<li><strong>query 方法：</strong> 接收用户输入的查询，通过向量化后在数据库中检索最相关的文档片段，并返回最匹配的文档。</li>\n</ul>\n<p>假设我们已经有一组文档片段存储在  <code>documents</code>  中，并且使用 OpenAI 的 Embedding API 进行向量化处理，以下是一个简化的运行示例：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 初始化文档列表</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>documents <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    <span class=\"token string\">\"机器学习是人工智能的一个分支。\"</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    <span class=\"token string\">\"深度学习是一种特殊的机器学习方法。\"</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    <span class=\"token string\">\"监督学习是一种训练模型的方式。\"</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    <span class=\"token string\">\"强化学习通过奖励和惩罚进行学习。\"</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>    <span class=\"token string\">\"无监督学习不依赖标签数据。\"</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token punctuation\">]</span></pre></td></tr></table></figure><figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 创建向量数据库</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>vector_store <span class=\"token operator\">=</span> VectorStore<span class=\"token punctuation\">(</span>document<span class=\"token operator\">=</span>documents<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token comment\"># 使用 OpenAI Embedding 模型对文档进行向量化</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>embedding_model <span class=\"token operator\">=</span> OpenAIEmbedding<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre></pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token comment\"># 获取文档向量并存储</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>vector_store<span class=\"token punctuation\">.</span>get_vector<span class=\"token punctuation\">(</span>embedding_model<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre></pre></td></tr><tr><td data-num=\"10\"></td><td><pre><span class=\"token comment\"># 持久化存储到本地</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>vector_store<span class=\"token punctuation\">.</span>persist<span class=\"token punctuation\">(</span><span class=\"token string\">'storage'</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 模拟用户查询</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>query <span class=\"token operator\">=</span> <span class=\"token string\">\"什么是深度学习？\"</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>result <span class=\"token operator\">=</span> vector_store<span class=\"token punctuation\">.</span>query<span class=\"token punctuation\">(</span>query<span class=\"token punctuation\">,</span> embedding_model<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"检索结果：\"</span><span class=\"token punctuation\">,</span> result<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><pre><code>检索结果： ['深度学习是一种特殊的机器学习方法。']\n</code></pre>\n<p>在上面这段代码中，npy 文件是 NumPy 库用于存储数组数据的文件格式。npy 文件能够高效地保存和加载 NumPy 数组，并保留数组的形状、数据类型等信息。它是一种二进制文件格式，用于序列化 NumPy 数组，使得存储和读取过程更加快速和便捷。</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>loaded_array <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span><span class=\"token string\">'./storage/vectors.npy'</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>loaded_array<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><pre><code>[[ 0.01502207  0.02491738 -0.00439076 ... -0.01719366 -0.0138915\n   0.01127215]\n [-0.01286558  0.02198915 -0.00355636 ... -0.01165039 -0.00909946\n  -0.0171959 ]\n [-0.0233228   0.01815101 -0.0157143  ... -0.00236056  0.00593637\n   0.01614942]\n [-0.0254771   0.01967829 -0.00521657 ... -0.02507718 -0.00610462\n  -0.00051681]\n [ 0.03053524  0.00561556 -0.00861679 ... -0.00738284 -0.01472384\n   0.00989781]]\n</code></pre>\n<h3 id=\"5-大模型问答模块编写\"><a class=\"anchor\" href=\"#5-大模型问答模块编写\">#</a> 5. 大模型问答模块编写</h3>\n<p>  现在我们已经构建了向量数据库和检索模块，接下来我们将实现大模型模块，用于根据检索到的相关文档片段生成对用户问题的回答。为了简化和便于扩展，我们会先实现一个基类  <code>BaseModel</code> ，然后再以 <strong>GPT4o</strong> 模型为例，展示如何使用大语言模型来完成这个任务。</p>\n<h4 id=\"51-大模型模块的基类\"><a class=\"anchor\" href=\"#51-大模型模块的基类\">#</a> 5.1 大模型模块的基类</h4>\n<p>  这里我们先编写一个基类  <code>BaseModel</code> ，它包含两个主要方法：</p>\n<ul>\n<li><code>chat</code> ：负责处理用户的输入并生成回答。</li>\n<li><code>load_model</code> ：如果是使用本地模型，这个方法负责加载模型。如果使用 API 模型（如 OpenAI），可以不用实现这个方法。</li>\n</ul>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">class</span> <span class=\"token class-name\">BaseModel</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    基础模型类，作为所有模型的基类。</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    包含一些通用的接口，如加载模型、生成回答等。</pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    \"\"\"</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> path<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span> <span class=\"token operator\">=</span> <span class=\"token string\">''</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>        self<span class=\"token punctuation\">.</span>path <span class=\"token operator\">=</span> path  <span class=\"token comment\"># 用于存储模型文件的路径，默认为空。</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">chat</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> prompt<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">,</span> history<span class=\"token punctuation\">:</span> List<span class=\"token punctuation\">[</span><span class=\"token builtin\">dict</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> content<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>        <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"11\"></td><td><pre>        使用模型生成回答的抽象方法。</pre></td></tr><tr><td data-num=\"12\"></td><td><pre>        :param prompt: 用户的提问内容</pre></td></tr><tr><td data-num=\"13\"></td><td><pre>        :param history: 之前的对话历史（字典列表）</pre></td></tr><tr><td data-num=\"14\"></td><td><pre>        :param content: 提供的上下文内容</pre></td></tr><tr><td data-num=\"15\"></td><td><pre>        :return: 模型生成的答案</pre></td></tr><tr><td data-num=\"16\"></td><td><pre>        \"\"\"</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>        <span class=\"token keyword\">pass</span>  <span class=\"token comment\"># 具体的实现由子类提供</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre></pre></td></tr><tr><td data-num=\"19\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">load_model</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>        <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"21\"></td><td><pre>        加载模型的方法，通常用于本地模型。</pre></td></tr><tr><td data-num=\"22\"></td><td><pre>        \"\"\"</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre>        <span class=\"token keyword\">pass</span>  <span class=\"token comment\"># 如果是 API 模型，可能不需要实现</span></pre></td></tr></table></figure><h4 id=\"52-借助gpt4o模型进行对话\"><a class=\"anchor\" href=\"#52-借助gpt4o模型进行对话\">#</a> 5.2 借助 GPT4o 模型进行对话</h4>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">class</span> <span class=\"token class-name\">GPT4oChat</span><span class=\"token punctuation\">(</span>BaseModel<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    基于 GPT-4o 模型的对话类，继承自 BaseModel。</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    主要用于通过 OpenAI API 来生成对话回答。</pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    \"\"\"</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> api_key<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">,</span> base_url<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span> <span class=\"token operator\">=</span> <span class=\"token string\">\"https://ai.devtool.tech/proxy/v1\"</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>        <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"8\"></td><td><pre>        初始化 GPT-4o 模型。</pre></td></tr><tr><td data-num=\"9\"></td><td><pre>        :param api_key: OpenAI API 的密钥</pre></td></tr><tr><td data-num=\"10\"></td><td><pre>        :param base_url: 用于访问 OpenAI API 的基础 URL，默认为代理 URL</pre></td></tr><tr><td data-num=\"11\"></td><td><pre>        \"\"\"</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>        self<span class=\"token punctuation\">.</span>client <span class=\"token operator\">=</span> OpenAI<span class=\"token punctuation\">(</span>api_key<span class=\"token operator\">=</span>api_key<span class=\"token punctuation\">,</span> base_url<span class=\"token operator\">=</span>base_url<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 初始化 OpenAI 客户端</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">chat</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> prompt<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">,</span> history<span class=\"token punctuation\">:</span> List <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> content<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span> <span class=\"token operator\">=</span> <span class=\"token string\">''</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>        <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"17\"></td><td><pre>        使用 GPT-4o 生成回答。</pre></td></tr><tr><td data-num=\"18\"></td><td><pre>        :param prompt: 用户的提问</pre></td></tr><tr><td data-num=\"19\"></td><td><pre>        :param history: 之前的对话历史（可选）</pre></td></tr><tr><td data-num=\"20\"></td><td><pre>        :param content: 可参考的上下文信息（可选）</pre></td></tr><tr><td data-num=\"21\"></td><td><pre>        :return: 生成的回答</pre></td></tr><tr><td data-num=\"22\"></td><td><pre>        \"\"\"</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre>        <span class=\"token comment\"># 构建包含问题和上下文的完整提示</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre>        full_prompt <span class=\"token operator\">=</span> PROMPT_TEMPLATE<span class=\"token punctuation\">[</span><span class=\"token string\">'GPT4o_PROMPT_TEMPLATE'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>question<span class=\"token operator\">=</span>prompt<span class=\"token punctuation\">,</span> context<span class=\"token operator\">=</span>content<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"25\"></td><td><pre></pre></td></tr><tr><td data-num=\"26\"></td><td><pre>        <span class=\"token comment\"># 调用 GPT-4o 模型进行推理</span></pre></td></tr><tr><td data-num=\"27\"></td><td><pre>        response <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>client<span class=\"token punctuation\">.</span>chat<span class=\"token punctuation\">.</span>completions<span class=\"token punctuation\">.</span>create<span class=\"token punctuation\">(</span></pre></td></tr><tr><td data-num=\"28\"></td><td><pre>            model<span class=\"token operator\">=</span><span class=\"token string\">\"gpt-4o-mini\"</span><span class=\"token punctuation\">,</span>  <span class=\"token comment\"># 使用 GPT-4o 小型模型</span></pre></td></tr><tr><td data-num=\"29\"></td><td><pre>            messages<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span></pre></td></tr><tr><td data-num=\"30\"></td><td><pre>                <span class=\"token punctuation\">&#123;</span><span class=\"token string\">\"role\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"user\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"content\"</span><span class=\"token punctuation\">:</span> full_prompt<span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"31\"></td><td><pre>            <span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"32\"></td><td><pre>        <span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"33\"></td><td><pre></pre></td></tr><tr><td data-num=\"34\"></td><td><pre>        <span class=\"token comment\"># 返回模型生成的第一个回答</span></pre></td></tr><tr><td data-num=\"35\"></td><td><pre>        <span class=\"token keyword\">return</span> response<span class=\"token punctuation\">.</span>choices<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>message<span class=\"token punctuation\">.</span>content</pre></td></tr></table></figure><h4 id=\"53-提示模板\"><a class=\"anchor\" href=\"#53-提示模板\">#</a> 5.3 提示模板</h4>\n<p>  为了方便维护和复用提示语，可以使用一个字典来保存不同模型的提示模板。在这里我们为  <code>GPT4o</code>  定义了一个模板：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>PROMPT_TEMPLATE <span class=\"token operator\">=</span> <span class=\"token builtin\">dict</span><span class=\"token punctuation\">(</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    GPT4o_PROMPT_TEMPLATE<span class=\"token operator\">=</span><span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    下面有一个或许与这个问题相关的参考段落，若你觉得参考段落能和问题相关，则先总结参考段落的内容。</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    若你觉得参考段落和问题无关，则使用你自己的原始知识来回答用户的问题，并且总是使用中文来进行回答。</pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    问题: &#123;question&#125;</pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    可参考的上下文：</pre></td></tr><tr><td data-num=\"7\"></td><td><pre>    ···</pre></td></tr><tr><td data-num=\"8\"></td><td><pre>    &#123;context&#125;</pre></td></tr><tr><td data-num=\"9\"></td><td><pre>    ···</pre></td></tr><tr><td data-num=\"10\"></td><td><pre>    有用的回答:\"\"\"</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><h3 id=\"6-rag-demo完整流程演示\"><a class=\"anchor\" href=\"#6-rag-demo完整流程演示\">#</a> 6. RAG Demo 完整流程演示</h3>\n<p>  接下来，我们展示一个完整的 RAG Demo，结合我们前面实现的向量检索和大模型模块，展示如何在实际应用中使用 RAG 模型来回答问题。</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 加载并切分文档</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>docs <span class=\"token operator\">=</span> ReadFiles<span class=\"token punctuation\">(</span><span class=\"token string\">'./data'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>get_content<span class=\"token punctuation\">(</span>max_token_len<span class=\"token operator\">=</span><span class=\"token number\">600</span><span class=\"token punctuation\">,</span> cover_content<span class=\"token operator\">=</span><span class=\"token number\">150</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>vector <span class=\"token operator\">=</span> VectorStore<span class=\"token punctuation\">(</span>docs<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 使用 OpenAI Embedding 模型进行向量化</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>embedding <span class=\"token operator\">=</span> OpenAIEmbedding<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>vector<span class=\"token punctuation\">.</span>get_vector<span class=\"token punctuation\">(</span>EmbeddingModel<span class=\"token operator\">=</span>embedding<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><pre><code>[[-0.008657793514430523,-0.02245156653225422,0.00038487091660499573,-0.0024040460120886564,0.015111145563423634,...]]\n</code></pre>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 将向量和文档保存到本地</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>vector<span class=\"token punctuation\">.</span>persist<span class=\"token punctuation\">(</span>path<span class=\"token operator\">=</span><span class=\"token string\">'storage'</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 用户提出问题</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>question <span class=\"token operator\">=</span> <span class=\"token string\">'如何选择Jupyer的Kernel？'</span></pre></td></tr></table></figure><figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 在数据库中检索最相关的文档片段</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>content <span class=\"token operator\">=</span> vector<span class=\"token punctuation\">.</span>query<span class=\"token punctuation\">(</span>question<span class=\"token punctuation\">,</span> EmbeddingModel<span class=\"token operator\">=</span>embedding<span class=\"token punctuation\">,</span> k<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span></pre></td></tr></table></figure><figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>content</pre></td></tr></table></figure><pre><code>'b：\\n\\nbash\\njupyterlab\\n\\n在JupyterLab中选择虚拟环境的Kernel\\n打开一个新的notebook，然后在右上角的Kernel选项中选择“Python(myenv)”Kernel。现在，你的notebook将在你的虚拟环境中运行。\\n\\n结束工作\\n完成工作后，记得退出虚拟环境：\\nbashcondadeactivate\\n'\n</code></pre>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 使用 GPT4oChat 模型生成答案</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>chat <span class=\"token operator\">=</span> GPT4oChat<span class=\"token punctuation\">(</span>api_key <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>getenv<span class=\"token punctuation\">(</span><span class=\"token string\">\"OPENAI_API_KEY\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 传入 OpenAI API 密钥</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>chat<span class=\"token punctuation\">.</span>chat<span class=\"token punctuation\">(</span>question<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> content<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><pre><code>参考段落主要讲述了如何在JupyterLab中选择特定的Python虚拟环境作为Kernel。用户需要打开一个新的notebook，然后在右上角的Kernel选项中选择相应的虚拟环境（如“Python(myenv)”）。这样，notebook就会在所选的虚拟环境中运行。此外，段落还提到完成工作后应该如何退出虚拟环境。\n\n针对问题“如何选择Jupyter的Kernel”，可以总结为以下步骤：\n\n1. 打开Jupyter Notebook或JupyterLab。\n2. 创建一个新的notebook。\n3. 在右上角找到Kernel选项。\n4. 从下拉菜单中选择想要使用的Kernel，例如选择对应的虚拟环境。\n5. 如果需要，完成工作后记得退出虚拟环境。\n\n遵循这些步骤，你就可以成功选择所需的Kernel来运行你的notebook了。\n</code></pre>\n<ul>\n<li>完整函数封装</li>\n</ul>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">run_mini_rag</span><span class=\"token punctuation\">(</span>question<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">,</span> knowledge_base_path<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">,</span> k<span class=\"token punctuation\">:</span> <span class=\"token builtin\">int</span> <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    运行一个简化版的RAG项目。</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    </pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    :param question: 用户提出的问题</pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    :param knowledge_base_path: 知识库的路径，包含文档的文件夹路径</pre></td></tr><tr><td data-num=\"7\"></td><td><pre>    :param api_key: OpenAI API密钥，用于调用GPT-4o模型</pre></td></tr><tr><td data-num=\"8\"></td><td><pre>    :param k: 返回与问题最相关的k个文档片段，默认为1</pre></td></tr><tr><td data-num=\"9\"></td><td><pre>    :return: 返回GPT-4o模型生成的回答</pre></td></tr><tr><td data-num=\"10\"></td><td><pre>    \"\"\"</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>    api_key <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>getenv<span class=\"token punctuation\">(</span><span class=\"token string\">\"OPENAI_API_KEY\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>    <span class=\"token comment\"># 1. 加载并切分文档</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>    docs <span class=\"token operator\">=</span> ReadFiles<span class=\"token punctuation\">(</span>knowledge_base_path<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>get_content<span class=\"token punctuation\">(</span>max_token_len<span class=\"token operator\">=</span><span class=\"token number\">600</span><span class=\"token punctuation\">,</span> cover_content<span class=\"token operator\">=</span><span class=\"token number\">150</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>    vector <span class=\"token operator\">=</span> VectorStore<span class=\"token punctuation\">(</span>docs<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>    <span class=\"token comment\"># 2. 使用 OpenAI Embedding 模型进行向量化</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>    embedding <span class=\"token operator\">=</span> OpenAIEmbedding<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>    vector<span class=\"token punctuation\">.</span>get_vector<span class=\"token punctuation\">(</span>EmbeddingModel<span class=\"token operator\">=</span>embedding<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>    <span class=\"token comment\"># 3. 将向量和文档保存到本地（可选）</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>    vector<span class=\"token punctuation\">.</span>persist<span class=\"token punctuation\">(</span>path<span class=\"token operator\">=</span><span class=\"token string\">'storage'</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre></pre></td></tr><tr><td data-num=\"23\"></td><td><pre>    <span class=\"token comment\"># 4. 在数据库中检索最相关的文档片段</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre>    content <span class=\"token operator\">=</span> vector<span class=\"token punctuation\">.</span>query<span class=\"token punctuation\">(</span>question<span class=\"token punctuation\">,</span> EmbeddingModel<span class=\"token operator\">=</span>embedding<span class=\"token punctuation\">,</span> k<span class=\"token operator\">=</span>k<span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"25\"></td><td><pre></pre></td></tr><tr><td data-num=\"26\"></td><td><pre>    <span class=\"token comment\"># 5. 使用 GPT-4o 生成答案</span></pre></td></tr><tr><td data-num=\"27\"></td><td><pre>    chat <span class=\"token operator\">=</span> GPT4oChat<span class=\"token punctuation\">(</span>api_key<span class=\"token operator\">=</span>api_key<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"28\"></td><td><pre>    answer <span class=\"token operator\">=</span> chat<span class=\"token punctuation\">.</span>chat<span class=\"token punctuation\">(</span>question<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> content<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"29\"></td><td><pre>    </pre></td></tr><tr><td data-num=\"30\"></td><td><pre>    <span class=\"token keyword\">return</span> answer</pre></td></tr></table></figure><figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>question <span class=\"token operator\">=</span> <span class=\"token string\">'请问我应该如何在安装OpenAI库的时候设置代理呢？'</span></pre></td></tr></table></figure><figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>knowledge_base_path <span class=\"token operator\">=</span> <span class=\"token string\">'./data'</span></pre></td></tr></table></figure><figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>answer <span class=\"token operator\">=</span> run_mini_rag<span class=\"token punctuation\">(</span>question<span class=\"token punctuation\">,</span> knowledge_base_path<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>display<span class=\"token punctuation\">(</span>Markdown<span class=\"token punctuation\">(</span>answer<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p>参考段落的内容主要介绍了在虚拟环境中安装 OpenAI 库及其他相关库时，如何设置代理。具体步骤包括在命令行中设置 HTTP 和 HTTPS 代理，然后使用 pip 命令安装 OpenAI 库的指定版本和其他需要的库。</p>\n<p>为了在安装 OpenAI 库的时候设置代理，可以按照以下步骤操作：</p>\n<ol>\n<li>\n<p>打开终端或命令行界面。</p>\n</li>\n<li>\n<p>设置 HTTP 和 HTTPS 代理。使用以下命令：</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token builtin class-name\">set</span> <span class=\"token assign-left variable\">HTTP_PROXY</span><span class=\"token operator\">=</span>http://YOUR_PROXY_IP:YOUR_PROXY_PORT</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token builtin class-name\">set</span> <span class=\"token assign-left variable\">HTTPS_PROXY</span><span class=\"token operator\">=</span>https://YOUR_PROXY_IP:YOUR_PROXY_PORT</pre></td></tr></table></figure><p>请将 <code>YOUR_PROXY_IP</code>  和 <code>YOUR_PROXY_PORT</code>  替换为你所使用的代理地址和端口号。</p>\n</li>\n<li>\n<p>然后执行安装 OpenAI 库的命令：</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>pip <span class=\"token function\">install</span> <span class=\"token assign-left variable\">openai</span><span class=\"token operator\">==</span><span class=\"token number\">0.28</span>.1</pre></td></tr></table></figure></li>\n<li>\n<p>根据需要，你还可以安装其他相关库，使用类似命令进行安装。</p>\n</li>\n</ol>\n<p>通过这些步骤，你就可以在设置了代理的情况下成功安装 OpenAI 库。</p>\n<h2 id=\"三-基于langchain的rag系统demo示例\"><a class=\"anchor\" href=\"#三-基于langchain的rag系统demo示例\">#</a> 三、基于 LangChain 的 RAG 系统 Demo 示例</h2>\n<p>  理解了在 <code>LangChain</code>  中构建 <code>RAG</code>  的基本原理后，我们就可以开始动手实践了。接下来的案例中，我们通过  <code>Streamlit</code>  前端界面，结合  <code>LangChain</code>  框架 与  <code>DashScope</code>  向量嵌入服务，实现了一个轻量化的  <code>RAG（Retrieval-Augmented Generation）</code>  智能问答系统，支持上传多个  <code>PDF</code>  文档，系统将自动完成文本提取、分块、向量化，并构建基于  <code>FAISS</code>  的检索数据库。用户随后可以在页面中输入任意问题，系统会调用大语言模型（如  <code>DeepSeek-Chat</code> ）对  <code>PDF</code>  内容进行语义理解和回答生成。</p>\n<p>  其完整代码如下所示：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># ! pip install streamlit PyPDF2 dashscope faiss-cpu</span></pre></td></tr></table></figure><figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">import</span> streamlit <span class=\"token keyword\">as</span> st</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    <span class=\"token keyword\">from</span> PyPDF2 <span class=\"token keyword\">import</span> PdfReader</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    <span class=\"token keyword\">from</span> langchain<span class=\"token punctuation\">.</span>text_splitter <span class=\"token keyword\">import</span> RecursiveCharacterTextSplitter</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    <span class=\"token keyword\">from</span> langchain_core<span class=\"token punctuation\">.</span>prompts <span class=\"token keyword\">import</span> ChatPromptTemplate</pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    <span class=\"token keyword\">from</span> langchain_community<span class=\"token punctuation\">.</span>vectorstores <span class=\"token keyword\">import</span> FAISS</pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    <span class=\"token keyword\">from</span> langchain<span class=\"token punctuation\">.</span>tools<span class=\"token punctuation\">.</span>retriever <span class=\"token keyword\">import</span> create_retriever_tool</pre></td></tr><tr><td data-num=\"7\"></td><td><pre>    <span class=\"token keyword\">from</span> langchain<span class=\"token punctuation\">.</span>agents <span class=\"token keyword\">import</span> AgentExecutor<span class=\"token punctuation\">,</span> create_tool_calling_agent</pre></td></tr><tr><td data-num=\"8\"></td><td><pre>    <span class=\"token keyword\">from</span> langchain_community<span class=\"token punctuation\">.</span>embeddings <span class=\"token keyword\">import</span> DashScopeEmbeddings</pre></td></tr><tr><td data-num=\"9\"></td><td><pre>    <span class=\"token keyword\">from</span> langchain<span class=\"token punctuation\">.</span>chat_models <span class=\"token keyword\">import</span> init_chat_model</pre></td></tr><tr><td data-num=\"10\"></td><td><pre>    <span class=\"token keyword\">import</span> os</pre></td></tr><tr><td data-num=\"11\"></td><td><pre>    <span class=\"token keyword\">from</span> dotenv <span class=\"token keyword\">import</span> load_dotenv </pre></td></tr><tr><td data-num=\"12\"></td><td><pre>    load_dotenv<span class=\"token punctuation\">(</span>override<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre></pre></td></tr><tr><td data-num=\"14\"></td><td><pre></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>    DeepSeek_API_KEY <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>getenv<span class=\"token punctuation\">(</span><span class=\"token string\">\"DEEPSEEK_API_KEY\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>    dashscope_api_key <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>getenv<span class=\"token punctuation\">(</span><span class=\"token string\">\"dashscope_api_key\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>    os<span class=\"token punctuation\">.</span>environ<span class=\"token punctuation\">[</span><span class=\"token string\">\"KMP_DUPLICATE_LIB_OK\"</span><span class=\"token punctuation\">]</span><span class=\"token operator\">=</span><span class=\"token string\">\"TRUE\"</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre></pre></td></tr><tr><td data-num=\"20\"></td><td><pre></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>    embeddings <span class=\"token operator\">=</span> DashScopeEmbeddings<span class=\"token punctuation\">(</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre>        model<span class=\"token operator\">=</span><span class=\"token string\">\"text-embedding-v1\"</span><span class=\"token punctuation\">,</span> dashscope_api_key<span class=\"token operator\">=</span>dashscope_api_key</pre></td></tr><tr><td data-num=\"23\"></td><td><pre>    <span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre></pre></td></tr><tr><td data-num=\"25\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">pdf_read</span><span class=\"token punctuation\">(</span>pdf_doc<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"26\"></td><td><pre>        text <span class=\"token operator\">=</span> <span class=\"token string\">\"\"</span></pre></td></tr><tr><td data-num=\"27\"></td><td><pre>        <span class=\"token keyword\">for</span> pdf <span class=\"token keyword\">in</span> pdf_doc<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"28\"></td><td><pre>            pdf_reader <span class=\"token operator\">=</span> PdfReader<span class=\"token punctuation\">(</span>pdf<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"29\"></td><td><pre>            <span class=\"token keyword\">for</span> page <span class=\"token keyword\">in</span> pdf_reader<span class=\"token punctuation\">.</span>pages<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"30\"></td><td><pre>                text <span class=\"token operator\">+=</span> page<span class=\"token punctuation\">.</span>extract_text<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"31\"></td><td><pre>        <span class=\"token keyword\">return</span> text</pre></td></tr><tr><td data-num=\"32\"></td><td><pre></pre></td></tr><tr><td data-num=\"33\"></td><td><pre></pre></td></tr><tr><td data-num=\"34\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">get_chunks</span><span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"35\"></td><td><pre>        text_splitter <span class=\"token operator\">=</span> RecursiveCharacterTextSplitter<span class=\"token punctuation\">(</span>chunk_size<span class=\"token operator\">=</span><span class=\"token number\">1000</span><span class=\"token punctuation\">,</span> chunk_overlap<span class=\"token operator\">=</span><span class=\"token number\">200</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"36\"></td><td><pre>        chunks <span class=\"token operator\">=</span> text_splitter<span class=\"token punctuation\">.</span>split_text<span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"37\"></td><td><pre>        <span class=\"token keyword\">return</span> chunks</pre></td></tr><tr><td data-num=\"38\"></td><td><pre></pre></td></tr><tr><td data-num=\"39\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">vector_store</span><span class=\"token punctuation\">(</span>text_chunks<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"40\"></td><td><pre>        vector_store <span class=\"token operator\">=</span> FAISS<span class=\"token punctuation\">.</span>from_texts<span class=\"token punctuation\">(</span>text_chunks<span class=\"token punctuation\">,</span> embedding<span class=\"token operator\">=</span>embeddings<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"41\"></td><td><pre>        vector_store<span class=\"token punctuation\">.</span>save_local<span class=\"token punctuation\">(</span><span class=\"token string\">\"faiss_db\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"42\"></td><td><pre></pre></td></tr><tr><td data-num=\"43\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">get_conversational_chain</span><span class=\"token punctuation\">(</span>tools<span class=\"token punctuation\">,</span> ques<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"44\"></td><td><pre>        llm <span class=\"token operator\">=</span> init_chat_model<span class=\"token punctuation\">(</span><span class=\"token string\">\"deepseek-chat\"</span><span class=\"token punctuation\">,</span> model_provider<span class=\"token operator\">=</span><span class=\"token string\">\"deepseek\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"45\"></td><td><pre>        prompt <span class=\"token operator\">=</span> ChatPromptTemplate<span class=\"token punctuation\">.</span>from_messages<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span></pre></td></tr><tr><td data-num=\"46\"></td><td><pre>            <span class=\"token punctuation\">(</span></pre></td></tr><tr><td data-num=\"47\"></td><td><pre>                <span class=\"token string\">\"system\"</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"48\"></td><td><pre>                <span class=\"token triple-quoted-string string\">\"\"\"你是AI助手，请根据提供的上下文回答问题，确保提供所有细节，如果答案不在上下文中，请说\"答案不在上下文中\"，不要提供错误的答案\"\"\"</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"49\"></td><td><pre>            <span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"50\"></td><td><pre>            <span class=\"token punctuation\">(</span><span class=\"token string\">\"placeholder\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"&#123;chat_history&#125;\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"51\"></td><td><pre>            <span class=\"token punctuation\">(</span><span class=\"token string\">\"human\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"&#123;input&#125;\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"52\"></td><td><pre>            <span class=\"token punctuation\">(</span><span class=\"token string\">\"placeholder\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"&#123;agent_scratchpad&#125;\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"53\"></td><td><pre>        <span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"54\"></td><td><pre>        </pre></td></tr><tr><td data-num=\"55\"></td><td><pre>        tool <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>tools<span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"56\"></td><td><pre>        agent <span class=\"token operator\">=</span> create_tool_calling_agent<span class=\"token punctuation\">(</span>llm<span class=\"token punctuation\">,</span> tool<span class=\"token punctuation\">,</span> prompt<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"57\"></td><td><pre>        agent_executor <span class=\"token operator\">=</span> AgentExecutor<span class=\"token punctuation\">(</span>agent<span class=\"token operator\">=</span>agent<span class=\"token punctuation\">,</span> tools<span class=\"token operator\">=</span>tool<span class=\"token punctuation\">,</span> verbose<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"58\"></td><td><pre>        </pre></td></tr><tr><td data-num=\"59\"></td><td><pre>        response <span class=\"token operator\">=</span> agent_executor<span class=\"token punctuation\">.</span>invoke<span class=\"token punctuation\">(</span><span class=\"token punctuation\">&#123;</span><span class=\"token string\">\"input\"</span><span class=\"token punctuation\">:</span> ques<span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"60\"></td><td><pre>        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>response<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"61\"></td><td><pre>        st<span class=\"token punctuation\">.</span>write<span class=\"token punctuation\">(</span><span class=\"token string\">\"🤖 回答: \"</span><span class=\"token punctuation\">,</span> response<span class=\"token punctuation\">[</span><span class=\"token string\">'output'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"62\"></td><td><pre></pre></td></tr><tr><td data-num=\"63\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">check_database_exists</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"64\"></td><td><pre>        <span class=\"token triple-quoted-string string\">\"\"\"检查FAISS数据库是否存在\"\"\"</span></pre></td></tr><tr><td data-num=\"65\"></td><td><pre>        <span class=\"token keyword\">return</span> os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>exists<span class=\"token punctuation\">(</span><span class=\"token string\">\"faiss_db\"</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">and</span> os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>exists<span class=\"token punctuation\">(</span><span class=\"token string\">\"faiss_db/index.faiss\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"66\"></td><td><pre></pre></td></tr><tr><td data-num=\"67\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">user_input</span><span class=\"token punctuation\">(</span>user_question<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"68\"></td><td><pre>        <span class=\"token comment\"># 检查数据库是否存在</span></pre></td></tr><tr><td data-num=\"69\"></td><td><pre>        <span class=\"token keyword\">if</span> <span class=\"token keyword\">not</span> check_database_exists<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"70\"></td><td><pre>            st<span class=\"token punctuation\">.</span>error<span class=\"token punctuation\">(</span><span class=\"token string\">\"❌ 请先上传PDF文件并点击'Submit &amp; Process'按钮来处理文档！\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"71\"></td><td><pre>            st<span class=\"token punctuation\">.</span>info<span class=\"token punctuation\">(</span><span class=\"token string\">\"💡 步骤：1️⃣ 上传PDF → 2️⃣ 点击处理 → 3️⃣ 开始提问\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"72\"></td><td><pre>            <span class=\"token keyword\">return</span></pre></td></tr><tr><td data-num=\"73\"></td><td><pre>        </pre></td></tr><tr><td data-num=\"74\"></td><td><pre>        <span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"75\"></td><td><pre>            <span class=\"token comment\"># 加载 FAISS 数据库</span></pre></td></tr><tr><td data-num=\"76\"></td><td><pre>            new_db <span class=\"token operator\">=</span> FAISS<span class=\"token punctuation\">.</span>load_local<span class=\"token punctuation\">(</span><span class=\"token string\">\"faiss_db\"</span><span class=\"token punctuation\">,</span> embeddings<span class=\"token punctuation\">,</span> allow_dangerous_deserialization<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"77\"></td><td><pre>            </pre></td></tr><tr><td data-num=\"78\"></td><td><pre>            retriever <span class=\"token operator\">=</span> new_db<span class=\"token punctuation\">.</span>as_retriever<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"79\"></td><td><pre>            retrieval_chain <span class=\"token operator\">=</span> create_retriever_tool<span class=\"token punctuation\">(</span>retriever<span class=\"token punctuation\">,</span> <span class=\"token string\">\"pdf_extractor\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"This tool is to give answer to queries from the pdf\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"80\"></td><td><pre>            get_conversational_chain<span class=\"token punctuation\">(</span>retrieval_chain<span class=\"token punctuation\">,</span> user_question<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"81\"></td><td><pre>            </pre></td></tr><tr><td data-num=\"82\"></td><td><pre>        <span class=\"token keyword\">except</span> Exception <span class=\"token keyword\">as</span> e<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"83\"></td><td><pre>            st<span class=\"token punctuation\">.</span>error<span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"❌ 加载数据库时出错: </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>e<span class=\"token punctuation\">)</span><span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"84\"></td><td><pre>            st<span class=\"token punctuation\">.</span>info<span class=\"token punctuation\">(</span><span class=\"token string\">\"请重新处理PDF文件\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"85\"></td><td><pre></pre></td></tr><tr><td data-num=\"86\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"87\"></td><td><pre>        st<span class=\"token punctuation\">.</span>set_page_config<span class=\"token punctuation\">(</span><span class=\"token string\">\"🤖 LangChain B站公开课 By九天Hector\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"88\"></td><td><pre>        st<span class=\"token punctuation\">.</span>header<span class=\"token punctuation\">(</span><span class=\"token string\">\"🤖 LangChain B站公开课 By九天Hector\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"89\"></td><td><pre>        </pre></td></tr><tr><td data-num=\"90\"></td><td><pre>        <span class=\"token comment\"># 显示数据库状态</span></pre></td></tr><tr><td data-num=\"91\"></td><td><pre>        col1<span class=\"token punctuation\">,</span> col2 <span class=\"token operator\">=</span> st<span class=\"token punctuation\">.</span>columns<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"92\"></td><td><pre>        </pre></td></tr><tr><td data-num=\"93\"></td><td><pre>        <span class=\"token keyword\">with</span> col1<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"94\"></td><td><pre>            <span class=\"token keyword\">if</span> check_database_exists<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"95\"></td><td><pre>            <span class=\"token keyword\">pass</span></pre></td></tr><tr><td data-num=\"96\"></td><td><pre>            <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"97\"></td><td><pre>                st<span class=\"token punctuation\">.</span>warning<span class=\"token punctuation\">(</span><span class=\"token string\">\"⚠️ 请先上传并处理PDF文件\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"98\"></td><td><pre>        </pre></td></tr><tr><td data-num=\"99\"></td><td><pre>        <span class=\"token keyword\">with</span> col2<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"100\"></td><td><pre>            <span class=\"token keyword\">if</span> st<span class=\"token punctuation\">.</span>button<span class=\"token punctuation\">(</span><span class=\"token string\">\"🗑️ 清除数据库\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"101\"></td><td><pre>                <span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"102\"></td><td><pre>                    <span class=\"token keyword\">import</span> shutil</pre></td></tr><tr><td data-num=\"103\"></td><td><pre>                    <span class=\"token keyword\">if</span> os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>exists<span class=\"token punctuation\">(</span><span class=\"token string\">\"faiss_db\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"104\"></td><td><pre>                        shutil<span class=\"token punctuation\">.</span>rmtree<span class=\"token punctuation\">(</span><span class=\"token string\">\"faiss_db\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"105\"></td><td><pre>                    st<span class=\"token punctuation\">.</span>success<span class=\"token punctuation\">(</span><span class=\"token string\">\"数据库已清除\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"106\"></td><td><pre>                    st<span class=\"token punctuation\">.</span>rerun<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"107\"></td><td><pre>                <span class=\"token keyword\">except</span> Exception <span class=\"token keyword\">as</span> e<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"108\"></td><td><pre>                    st<span class=\"token punctuation\">.</span>error<span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"清除失败: </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>e<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"109\"></td><td><pre></pre></td></tr><tr><td data-num=\"110\"></td><td><pre>        <span class=\"token comment\"># 用户问题输入</span></pre></td></tr><tr><td data-num=\"111\"></td><td><pre>        user_question <span class=\"token operator\">=</span> st<span class=\"token punctuation\">.</span>text_input<span class=\"token punctuation\">(</span><span class=\"token string\">\"💬 请输入问题\"</span><span class=\"token punctuation\">,</span> </pre></td></tr><tr><td data-num=\"112\"></td><td><pre>                                    placeholder<span class=\"token operator\">=</span><span class=\"token string\">\"例如：这个文档的主要内容是什么？\"</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"113\"></td><td><pre>                                    disabled<span class=\"token operator\">=</span><span class=\"token keyword\">not</span> check_database_exists<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"114\"></td><td><pre></pre></td></tr><tr><td data-num=\"115\"></td><td><pre>        <span class=\"token keyword\">if</span> user_question<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"116\"></td><td><pre>            <span class=\"token keyword\">if</span> check_database_exists<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"117\"></td><td><pre>                <span class=\"token keyword\">with</span> st<span class=\"token punctuation\">.</span>spinner<span class=\"token punctuation\">(</span><span class=\"token string\">\"🤔 AI正在分析文档...\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"118\"></td><td><pre>                    user_input<span class=\"token punctuation\">(</span>user_question<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"119\"></td><td><pre>            <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"120\"></td><td><pre>                st<span class=\"token punctuation\">.</span>error<span class=\"token punctuation\">(</span><span class=\"token string\">\"❌ 请先上传并处理PDF文件！\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"121\"></td><td><pre></pre></td></tr><tr><td data-num=\"122\"></td><td><pre>        <span class=\"token comment\"># 侧边栏</span></pre></td></tr><tr><td data-num=\"123\"></td><td><pre>        <span class=\"token keyword\">with</span> st<span class=\"token punctuation\">.</span>sidebar<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"124\"></td><td><pre>            st<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">\"📁 文档管理\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"125\"></td><td><pre>            </pre></td></tr><tr><td data-num=\"126\"></td><td><pre>            <span class=\"token comment\"># 显示当前状态</span></pre></td></tr><tr><td data-num=\"127\"></td><td><pre>            <span class=\"token keyword\">if</span> check_database_exists<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"128\"></td><td><pre>                st<span class=\"token punctuation\">.</span>success<span class=\"token punctuation\">(</span><span class=\"token string\">\"✅ 数据库状态：已就绪\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"129\"></td><td><pre>            <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"130\"></td><td><pre>                st<span class=\"token punctuation\">.</span>info<span class=\"token punctuation\">(</span><span class=\"token string\">\"📝 状态：等待上传PDF\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"131\"></td><td><pre>            </pre></td></tr><tr><td data-num=\"132\"></td><td><pre>            st<span class=\"token punctuation\">.</span>markdown<span class=\"token punctuation\">(</span><span class=\"token string\">\"---\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"133\"></td><td><pre>            </pre></td></tr><tr><td data-num=\"134\"></td><td><pre>            <span class=\"token comment\"># 文件上传</span></pre></td></tr><tr><td data-num=\"135\"></td><td><pre>            pdf_doc <span class=\"token operator\">=</span> st<span class=\"token punctuation\">.</span>file_uploader<span class=\"token punctuation\">(</span></pre></td></tr><tr><td data-num=\"136\"></td><td><pre>                <span class=\"token string\">\"📎 上传PDF文件\"</span><span class=\"token punctuation\">,</span> </pre></td></tr><tr><td data-num=\"137\"></td><td><pre>                accept_multiple_files<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"138\"></td><td><pre>                <span class=\"token builtin\">type</span><span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'pdf'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"139\"></td><td><pre>                <span class=\"token builtin\">help</span><span class=\"token operator\">=</span><span class=\"token string\">\"支持上传多个PDF文件\"</span></pre></td></tr><tr><td data-num=\"140\"></td><td><pre>            <span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"141\"></td><td><pre>            </pre></td></tr><tr><td data-num=\"142\"></td><td><pre>            <span class=\"token keyword\">if</span> pdf_doc<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"143\"></td><td><pre>                st<span class=\"token punctuation\">.</span>info<span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"📄 已选择 </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>pdf_doc<span class=\"token punctuation\">)</span><span class=\"token punctuation\">&#125;</span></span><span class=\"token string\"> 个文件\"</span></span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"144\"></td><td><pre>                <span class=\"token keyword\">for</span> i<span class=\"token punctuation\">,</span> pdf <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>pdf_doc<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"145\"></td><td><pre>                    st<span class=\"token punctuation\">.</span>write<span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"</span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>i<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">. </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>pdf<span class=\"token punctuation\">.</span>name<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"146\"></td><td><pre>            </pre></td></tr><tr><td data-num=\"147\"></td><td><pre>            <span class=\"token comment\"># 处理按钮</span></pre></td></tr><tr><td data-num=\"148\"></td><td><pre>            process_button <span class=\"token operator\">=</span> st<span class=\"token punctuation\">.</span>button<span class=\"token punctuation\">(</span></pre></td></tr><tr><td data-num=\"149\"></td><td><pre>                <span class=\"token string\">\"🚀 提交并处理\"</span><span class=\"token punctuation\">,</span> </pre></td></tr><tr><td data-num=\"150\"></td><td><pre>                disabled<span class=\"token operator\">=</span><span class=\"token keyword\">not</span> pdf_doc<span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"151\"></td><td><pre>                use_container_width<span class=\"token operator\">=</span><span class=\"token boolean\">True</span></pre></td></tr><tr><td data-num=\"152\"></td><td><pre>            <span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"153\"></td><td><pre>            </pre></td></tr><tr><td data-num=\"154\"></td><td><pre>            <span class=\"token keyword\">if</span> process_button<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"155\"></td><td><pre>                <span class=\"token keyword\">if</span> pdf_doc<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"156\"></td><td><pre>                    <span class=\"token keyword\">with</span> st<span class=\"token punctuation\">.</span>spinner<span class=\"token punctuation\">(</span><span class=\"token string\">\"📊 正在处理PDF文件...\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"157\"></td><td><pre>                        <span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"158\"></td><td><pre>                            <span class=\"token comment\"># 读取 PDF 内容</span></pre></td></tr><tr><td data-num=\"159\"></td><td><pre>                            raw_text <span class=\"token operator\">=</span> pdf_read<span class=\"token punctuation\">(</span>pdf_doc<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"160\"></td><td><pre>                            </pre></td></tr><tr><td data-num=\"161\"></td><td><pre>                            <span class=\"token keyword\">if</span> <span class=\"token keyword\">not</span> raw_text<span class=\"token punctuation\">.</span>strip<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"162\"></td><td><pre>                                st<span class=\"token punctuation\">.</span>error<span class=\"token punctuation\">(</span><span class=\"token string\">\"❌ 无法从PDF中提取文本，请检查文件是否有效\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"163\"></td><td><pre>                                <span class=\"token keyword\">return</span></pre></td></tr><tr><td data-num=\"164\"></td><td><pre>                            </pre></td></tr><tr><td data-num=\"165\"></td><td><pre>                            <span class=\"token comment\"># 分割文本</span></pre></td></tr><tr><td data-num=\"166\"></td><td><pre>                            text_chunks <span class=\"token operator\">=</span> get_chunks<span class=\"token punctuation\">(</span>raw_text<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"167\"></td><td><pre>                            st<span class=\"token punctuation\">.</span>info<span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"📝 文本已分割为 </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>text_chunks<span class=\"token punctuation\">)</span><span class=\"token punctuation\">&#125;</span></span><span class=\"token string\"> 个片段\"</span></span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"168\"></td><td><pre>                            </pre></td></tr><tr><td data-num=\"169\"></td><td><pre>                            <span class=\"token comment\"># 创建向量数据库</span></pre></td></tr><tr><td data-num=\"170\"></td><td><pre>                            vector_store<span class=\"token punctuation\">(</span>text_chunks<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"171\"></td><td><pre>                            </pre></td></tr><tr><td data-num=\"172\"></td><td><pre>                            st<span class=\"token punctuation\">.</span>success<span class=\"token punctuation\">(</span><span class=\"token string\">\"✅ PDF处理完成！现在可以开始提问了\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"173\"></td><td><pre>                            st<span class=\"token punctuation\">.</span>balloons<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"174\"></td><td><pre>                            st<span class=\"token punctuation\">.</span>rerun<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"175\"></td><td><pre>                            </pre></td></tr><tr><td data-num=\"176\"></td><td><pre>                        <span class=\"token keyword\">except</span> Exception <span class=\"token keyword\">as</span> e<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"177\"></td><td><pre>                            st<span class=\"token punctuation\">.</span>error<span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"❌ 处理PDF时出错: </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>e<span class=\"token punctuation\">)</span><span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"178\"></td><td><pre>                <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"179\"></td><td><pre>                    st<span class=\"token punctuation\">.</span>warning<span class=\"token punctuation\">(</span><span class=\"token string\">\"⚠️ 请先选择PDF文件\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"180\"></td><td><pre>            </pre></td></tr><tr><td data-num=\"181\"></td><td><pre>            <span class=\"token comment\"># 使用说明</span></pre></td></tr><tr><td data-num=\"182\"></td><td><pre>            <span class=\"token keyword\">with</span> st<span class=\"token punctuation\">.</span>expander<span class=\"token punctuation\">(</span><span class=\"token string\">\"💡 使用说明\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"183\"></td><td><pre>                st<span class=\"token punctuation\">.</span>markdown<span class=\"token punctuation\">(</span><span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"184\"></td><td><pre>                **步骤：**</pre></td></tr><tr><td data-num=\"185\"></td><td><pre>                1. 📎 上传一个或多个PDF文件</pre></td></tr><tr><td data-num=\"186\"></td><td><pre>                2. 🚀 点击\"Submit &amp; Process\"处理文档</pre></td></tr><tr><td data-num=\"187\"></td><td><pre>                3. 💬 在主页面输入您的问题</pre></td></tr><tr><td data-num=\"188\"></td><td><pre>                4. 🤖 AI将基于PDF内容回答问题</pre></td></tr><tr><td data-num=\"189\"></td><td><pre>                </pre></td></tr><tr><td data-num=\"190\"></td><td><pre>                **提示：**</pre></td></tr><tr><td data-num=\"191\"></td><td><pre>                - 支持多个PDF文件同时上传</pre></td></tr><tr><td data-num=\"192\"></td><td><pre>                - 处理大文件可能需要一些时间</pre></td></tr><tr><td data-num=\"193\"></td><td><pre>                - 可以随时清除数据库重新开始</pre></td></tr><tr><td data-num=\"194\"></td><td><pre>                \"\"\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"195\"></td><td><pre></pre></td></tr><tr><td data-num=\"196\"></td><td><pre>    <span class=\"token keyword\">if</span> __name__ <span class=\"token operator\">==</span> <span class=\"token string\">\"__main__\"</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"197\"></td><td><pre>        main<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p>基于此，我们能够实现：</p>\n<ul>\n<li><strong>LangChain 的多模块能力</strong>（向量搜索 + Agent 工具）</li>\n<li><strong>Streamlit 前端交互</strong></li>\n<li><strong>FAISS 向量数据库</strong></li>\n<li><strong>DashScope Embedding + DeepSeek 模型接入</strong></li>\n<li>并完成了完整的 RAG（检索增强生成）流程</li>\n</ul>\n<p>以下是各部分功能实现代码讲解：</p>\n<h3 id=\"1-导入库-环境初始化\"><a class=\"anchor\" href=\"#1-导入库-环境初始化\">#</a> 🔧 1. 导入库 &amp; 环境初始化</h3>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">import</span> streamlit <span class=\"token keyword\">as</span> st</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">from</span> PyPDF2 <span class=\"token keyword\">import</span> PdfReader</pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token keyword\">from</span> langchain<span class=\"token punctuation\">.</span>text_splitter <span class=\"token keyword\">import</span> RecursiveCharacterTextSplitter</pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>load_dotenv<span class=\"token punctuation\">(</span>override<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><ul>\n<li>\n<p><code>Streamlit</code>  用于构建网页界面。</p>\n</li>\n<li>\n<p><code>PyPDF2</code>  用来读取 PDF 文本。</p>\n</li>\n<li>\n<p><code>load_dotenv()</code>  加载  <code>.env</code>  中的 API Key，例如：</p>\n<pre><code class=\"language-dotenv\">DEEPSEEK_API_KEY=sk-xxx\nDASHSCOPE_API_KEY=xxx\n</code></pre>\n</li>\n</ul>\n<hr>\n<h3 id=\"2-加载-api-密钥与设置环境变量\"><a class=\"anchor\" href=\"#2-加载-api-密钥与设置环境变量\">#</a> 🔐 2. 加载 API 密钥与设置环境变量</h3>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>DeepSeek_API_KEY <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>getenv<span class=\"token punctuation\">(</span><span class=\"token string\">\"DEEPSEEK_API_KEY\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>dashscope_api_key <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>getenv<span class=\"token punctuation\">(</span><span class=\"token string\">\"dashscope_api_key\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>os<span class=\"token punctuation\">.</span>environ<span class=\"token punctuation\">[</span><span class=\"token string\">\"KMP_DUPLICATE_LIB_OK\"</span><span class=\"token punctuation\">]</span><span class=\"token operator\">=</span><span class=\"token string\">\"TRUE\"</span></pre></td></tr></table></figure><ul>\n<li>从环境变量中读取 DashScope 和 DeepSeek API。</li>\n<li>设置  <code>KMP_DUPLICATE_LIB_OK</code>  避免某些 MKL 多线程报错。</li>\n</ul>\n<hr>\n<h3 id=\"3-初始化向量-embedding-模型\"><a class=\"anchor\" href=\"#3-初始化向量-embedding-模型\">#</a> 🧠 3. 初始化向量 Embedding 模型</h3>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>embeddings <span class=\"token operator\">=</span> DashScopeEmbeddings<span class=\"token punctuation\">(</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    model<span class=\"token operator\">=</span><span class=\"token string\">\"text-embedding-v1\"</span><span class=\"token punctuation\">,</span> dashscope_api_key<span class=\"token operator\">=</span>dashscope_api_key</pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><ul>\n<li>用阿里云 DashScope 提供的  <code>text-embedding-v1</code>  将文本转为向量表示，用于相似度搜索。</li>\n</ul>\n<hr>\n<h3 id=\"4-处理-pdf-文本与向量化逻辑\"><a class=\"anchor\" href=\"#4-处理-pdf-文本与向量化逻辑\">#</a> 📄 4. 处理 PDF 文本与向量化逻辑</h3>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">pdf_read</span><span class=\"token punctuation\">(</span>pdf_doc<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">get_chunks</span><span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">vector_store</span><span class=\"token punctuation\">(</span>text_chunks<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span></pre></td></tr></table></figure><ul>\n<li><code>pdf_read</code> ：逐页读取 PDF 内容并拼接。</li>\n<li><code>get_chunks</code> ：将长文本切片为多个段落（chunk），每段 1000 字，重叠 200 字。</li>\n<li><code>vector_store</code> ：用 FAISS 建立向量索引，并保存到本地  <code>faiss_db/</code> 。</li>\n</ul>\n<hr>\n<h3 id=\"5-agent对话链-工具调用核心-rag\"><a class=\"anchor\" href=\"#5-agent对话链-工具调用核心-rag\">#</a> 🔁 5. Agent 对话链 + 工具调用（核心 RAG）</h3>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">get_conversational_chain</span><span class=\"token punctuation\">(</span>tools<span class=\"token punctuation\">,</span> ques<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    llm <span class=\"token operator\">=</span> init_chat_model<span class=\"token punctuation\">(</span><span class=\"token string\">\"deepseek-chat\"</span><span class=\"token punctuation\">,</span> model_provider<span class=\"token operator\">=</span><span class=\"token string\">\"deepseek\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    agent_executor <span class=\"token operator\">=</span> AgentExecutor<span class=\"token punctuation\">(</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    response <span class=\"token operator\">=</span> agent_executor<span class=\"token punctuation\">.</span>invoke<span class=\"token punctuation\">(</span><span class=\"token punctuation\">&#123;</span><span class=\"token string\">\"input\"</span><span class=\"token punctuation\">:</span> ques<span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span></pre></td></tr></table></figure><ul>\n<li>\n<p>初始化 DeepSeek 模型为 Agent。</p>\n</li>\n<li>\n<p>使用 LangChain 的  <code>create_tool_calling_agent</code>  构造 Agent，输入：</p>\n<ul>\n<li>prompt（你设定的系统角色）</li>\n<li>工具（retriever 工具）</li>\n</ul>\n</li>\n<li>\n<p><code>AgentExecutor.invoke</code> ：LangChain 自动判断是否调用工具，完成 “读取上下文 → 查询 → 回答” 流程。</p>\n</li>\n</ul>\n<hr>\n<h3 id=\"6-用户提问逻辑调用-faiss\"><a class=\"anchor\" href=\"#6-用户提问逻辑调用-faiss\">#</a> 🔍 6. 用户提问逻辑（调用 FAISS）</h3>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">user_input</span><span class=\"token punctuation\">(</span>user_question<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    new_db <span class=\"token operator\">=</span> FAISS<span class=\"token punctuation\">.</span>load_local<span class=\"token punctuation\">(</span><span class=\"token string\">\"faiss_db\"</span><span class=\"token punctuation\">,</span> embeddings<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    retriever <span class=\"token operator\">=</span> new_db<span class=\"token punctuation\">.</span>as_retriever<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    retrieval_chain <span class=\"token operator\">=</span> create_retriever_tool<span class=\"token punctuation\">(</span>retriever<span class=\"token punctuation\">,</span> <span class=\"token string\">\"pdf_extractor\"</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    get_conversational_chain<span class=\"token punctuation\">(</span>retrieval_chain<span class=\"token punctuation\">,</span> user_question<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><ul>\n<li>加载本地 FAISS 向量库；</li>\n<li>将其转为 LangChain 的检索工具；</li>\n<li>交由 Agent 调用完成回答。</li>\n</ul>\n<hr>\n<h3 id=\"7-检查数据库是否存在\"><a class=\"anchor\" href=\"#7-检查数据库是否存在\">#</a> 🧠 7. 检查数据库是否存在</h3>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">check_database_exists</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    <span class=\"token keyword\">return</span> os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>exists<span class=\"token punctuation\">(</span><span class=\"token string\">\"faiss_db\"</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">and</span> os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>exists<span class=\"token punctuation\">(</span><span class=\"token string\">\"faiss_db/index.faiss\"</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p>简单检查本地是否已有向量化数据。</p>\n<hr>\n<h3 id=\"8-主界面逻辑streamlit\"><a class=\"anchor\" href=\"#8-主界面逻辑streamlit\">#</a> 🌐 8. 主界面逻辑（Streamlit）</h3>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    st<span class=\"token punctuation\">.</span>set_page_config<span class=\"token punctuation\">(</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span></pre></td></tr></table></figure><ul>\n<li>\n<p>页面标题与界面配置。</p>\n</li>\n<li>\n<p><code>st.columns</code>  分栏：左边显示提示，右边放置 “清空数据库” 按钮。</p>\n</li>\n<li>\n<p>主输入框： <code>st.text_input(&quot;请输入问题&quot;)</code></p>\n<ul>\n<li>只有当数据库存在时才能提问。</li>\n</ul>\n</li>\n<li>\n<p>侧边栏：</p>\n<ul>\n<li>PDF 上传器；</li>\n<li>提交按钮（处理上传的 PDF → 分片 → 向量化 → 存储）。</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3 id=\"9-提交-pdf-后执行的逻辑\"><a class=\"anchor\" href=\"#9-提交-pdf-后执行的逻辑\">#</a> 🎯 9. 提交 PDF 后执行的逻辑</h3>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">if</span> process_button<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    raw_text <span class=\"token operator\">=</span> pdf_read<span class=\"token punctuation\">(</span>pdf_doc<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    text_chunks <span class=\"token operator\">=</span> get_chunks<span class=\"token punctuation\">(</span>raw_text<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    vector_store<span class=\"token punctuation\">(</span>text_chunks<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><ul>\n<li>\n<p>当点击 “提交并处理” 后：</p>\n<ol>\n<li>读取上传的 PDF；</li>\n<li>切片文本；</li>\n<li>向量化入库；</li>\n<li>弹出气球提示，并  <code>st.rerun()</code>  刷新页面状态。</li>\n</ol>\n</li>\n</ul>\n<hr>\n<h4 id=\"项目结构总结\"><a class=\"anchor\" href=\"#项目结构总结\">#</a> 📎 项目结构总结</h4>\n<table>\n<thead>\n<tr>\n<th>模块</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>🧾 PDF 解析</td>\n<td>读取用户上传的 PDF</td>\n</tr>\n<tr>\n<td>✂️ 文本切片</td>\n<td>按段落分割内容</td>\n</tr>\n<tr>\n<td>📊 向量化</td>\n<td>DashScope Embedding + FAISS 建库</td>\n</tr>\n<tr>\n<td>🔁 查询接口</td>\n<td>用户输入 → 召回相关 chunk</td>\n</tr>\n<tr>\n<td>🤖 DeepSeek Agent</td>\n<td>调用检索工具并给出回答</td>\n</tr>\n<tr>\n<td>💻 UI 层</td>\n<td>Streamlit 实现全部交互</td>\n</tr>\n</tbody>\n</table>\n<p>  其中 LangChain RAG 核心功能相关代码如下：</p>\n<ul>\n<li>Step 1：PDF 文件上传与文本提取</li>\n</ul>\n<p>  使用  <code>st.file_uploader()</code>  组件支持多文件上传，并通过  <code>PyPDF2.PdfReader</code>  对每页内容进行提取，组合为整体文本。</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">pdf_read</span><span class=\"token punctuation\">(</span>pdf_doc<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>        text <span class=\"token operator\">=</span> <span class=\"token string\">\"\"</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>        <span class=\"token keyword\">for</span> pdf <span class=\"token keyword\">in</span> pdf_doc<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>            pdf_reader <span class=\"token operator\">=</span> PdfReader<span class=\"token punctuation\">(</span>pdf<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>            <span class=\"token keyword\">for</span> page <span class=\"token keyword\">in</span> pdf_reader<span class=\"token punctuation\">.</span>pages<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>                text <span class=\"token operator\">+=</span> page<span class=\"token punctuation\">.</span>extract_text<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>        <span class=\"token keyword\">return</span> text</pre></td></tr></table></figure><ul>\n<li>Step 2：文本分块与向量数据库构建</li>\n</ul>\n<p>  使用  <code>RecursiveCharacterTextSplitter</code>  将长文档切割为固定长度（1000 字）+ 重叠（200 字）的小块，将文本块通过  <code>DashScopeEmbeddings</code>  嵌入为向量，使用  <code>FAISS</code>  本地存储向量数据库。</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>chunks <span class=\"token operator\">=</span> text_splitter<span class=\"token punctuation\">.</span>split_text<span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    vector_store <span class=\"token operator\">=</span> FAISS<span class=\"token punctuation\">.</span>from_texts<span class=\"token punctuation\">(</span>chunks<span class=\"token punctuation\">,</span> embedding<span class=\"token operator\">=</span>embeddings<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    vector_store<span class=\"token punctuation\">.</span>save_local<span class=\"token punctuation\">(</span><span class=\"token string\">\"faiss_db\"</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><ul>\n<li>Step 3：用户提问与语义检索</li>\n</ul>\n<p>  通过  <code>Streamlit</code>  获取用户输入问题，如果向量数据库存在，则加载  <code>FAISS</code>  检索器，使用  <code>create_retriever_tool()</code>  构建  <code>LangChain</code>  工具，交由  <code>AgentExecutor</code>  执行，自动调用检索器并生成答案。</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>retrieval_chain <span class=\"token operator\">=</span> create_retriever_tool<span class=\"token punctuation\">(</span>retriever<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    agent <span class=\"token operator\">=</span> create_tool_calling_agent<span class=\"token punctuation\">(</span>llm<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span>retrieval_chain<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> prompt<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    response <span class=\"token operator\">=</span> agent_executor<span class=\"token punctuation\">.</span>invoke<span class=\"token punctuation\">(</span><span class=\"token punctuation\">&#123;</span><span class=\"token string\">\"input\"</span><span class=\"token punctuation\">:</span> ques<span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p>  项目运行效果如下所示：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">from</span> IPython<span class=\"token punctuation\">.</span>display <span class=\"token keyword\">import</span> Video</pre></td></tr></table></figure><figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>Video<span class=\"token punctuation\">(</span><span class=\"token string\">\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/LangChain%20RAG.mp4\"</span><span class=\"token punctuation\">,</span> width<span class=\"token operator\">=</span><span class=\"token number\">800</span><span class=\"token punctuation\">,</span> height<span class=\"token operator\">=</span><span class=\"token number\">400</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><video src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/LangChain%20RAG.mp4\" controls  width=\"800\"  height=\"400\">\n      Your browser does not support the <code>video</code> element.\n    </video>\n",
            "tags": [
                "大模型",
                "Python",
                "RGA",
                "Python"
            ]
        }
    ]
}